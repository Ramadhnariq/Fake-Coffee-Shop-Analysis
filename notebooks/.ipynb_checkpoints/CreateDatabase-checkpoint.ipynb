{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e548f14-08be-4809-b9e0-7cf422b2301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/site-packages (25.1.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: faker in /usr/local/lib/python3.11/site-packages (37.5.3)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/site-packages (1.32.3)\n",
      "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/site-packages (from faker) (2025.2)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m127.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.1.1\n",
      "    Uninstalling pip-25.1.1:\n",
      "      Successfully uninstalled pip-25.1.1\n",
      "Successfully installed pip-25.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip faker polars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74fde846-fda3-46eb-bfc1-fd8e7a7b9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Libraries ---\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import random\n",
    "from faker import Faker\n",
    "import polars as pl\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "FILE_PATH_STORES = \"stores.csv\"\n",
    "FILE_PATH_CATEGORIES = \"categories.csv\"\n",
    "FILE_PATH_PRODUCTS = \"products.csv\"\n",
    "FILE_PATH_TRANSACTIONS = \"transactions.csv\"\n",
    "\n",
    "\n",
    "# Initialize Faker with Indonesian locale\n",
    "fake = Faker(\"id_ID\")\n",
    "Faker.seed(42) \n",
    "\n",
    "\n",
    "N_ROWS_TRANSACTIONS = 1_000_000 \n",
    "N_CHUNKS = 10\n",
    "CHUNK_SIZE = N_ROWS_TRANSACTIONS // N_CHUNKS\n",
    "\n",
    "N_GENERATED_STORES = 50\n",
    "\n",
    "# Date range for transactions (one month)\n",
    "START_TRANSACTION_DATE = datetime(2023, 7, 1)\n",
    "END_TRANSACTION_DATE = datetime(2023, 7, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff5d862d-16c3-44f6-815b-4b5248efb62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stores_data(num_stores: int) -> pl.DataFrame:\n",
    "    print(\"Getting static products data...\")\n",
    "    store_data = [\n",
    "          {\"store_id\": 1, \"store_name\": \"Jue Coffee Kuningan City\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 2, \"store_name\": \"Jue Coffee Grand Indonesia\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 3, \"store_name\": \"Jue Coffee Senayan City\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 4, \"store_name\": \"Jue Coffee Pondok Indah Mall\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 5, \"store_name\": \"Jue Coffee Gandaria City\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 6, \"store_name\": \"Jue Coffee Pacific Place\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 7, \"store_name\": \"Jue Coffee Kota Kasablanka\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 8, \"store_name\": \"Jue Coffee Lotte Avenue\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 9, \"store_name\": \"Jue Coffee Plaza Senayan\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 10, \"store_name\": \"Jue Coffee Sarinah Thamrin\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 11, \"store_name\": \"Jue Coffee FX Sudirman\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 12, \"store_name\": \"Jue Coffee Central Park\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 13, \"store_name\": \"Jue Coffee Taman Anggrek\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 14, \"store_name\": \"Jue Coffee Puri Indah Mall\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 15, \"store_name\": \"Jue Coffee Mall Kelapa Gading\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 16, \"store_name\": \"Jue Coffee Emporium Pluit\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 17, \"store_name\": \"Jue Coffee PIK Avenue\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 18, \"store_name\": \"Jue Coffee Mall Artha Gading\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 19, \"store_name\": \"Jue Coffee One PM\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 20, \"store_name\": \"Jue Coffee SCBD\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 21, \"store_name\": \"Jue Coffee Kemang Village\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 22, \"store_name\": \"Jue Coffee Cilandak Town Square\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 23, \"store_name\": \"Jue Coffee Pejaten Village\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 24, \"store_name\": \"Jue Coffee Bintaro XChange\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 25, \"store_name\": \"Jue Coffee Transpark Bintaro\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 26, \"store_name\": \"Jue Coffee The Breeze BSD\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 27, \"store_name\": \"Jue Coffee Summarecon Mall Serpong\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 28, \"store_name\": \"Jue Coffee Living World Alam Sutera\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 29, \"store_name\": \"Jue Coffee Supermal Karawaci\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 30, \"store_name\": \"Jue Coffee Tangcity Mall\", \"city_name\": \"Kota Tangerang\"},\n",
    "          {\"store_id\": 31, \"store_name\": \"Jue Coffee AEON Mall BSD\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 32, \"store_name\": \"Jue Coffee IKEA Alam Sutera\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 33, \"store_name\": \"Jue Coffee Teras Kota BSD\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 34, \"store_name\": \"Jue Coffee Ciputat Raya\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 35, \"store_name\": \"Jue Coffee Pamulang\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 36, \"store_name\": \"Jue Coffee ITC BSD\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 37, \"store_name\": \"Jue Coffee Pasar Modern BSD\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 38, \"store_name\": \"Jue Coffee Gading Serpong\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 39, \"store_name\": \"Jue Coffee Mall @ Alam Sutera\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 40, \"store_name\": \"Jue Coffee Cikokol\", \"city_name\": \"Kota Tangerang\"},\n",
    "          {\"store_id\": 41, \"store_name\": \"Jue Coffee Graha Raya\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 42, \"store_name\": \"Jue Coffee Modernland Tangerang\", \"city_name\": \"Kota Tangerang\"},\n",
    "          {\"store_id\": 43, \"store_name\": \"Jue Coffee Alam Sutera Boulevard\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 44, \"store_name\": \"Jue Coffee Stasiun Tangerang\", \"city_name\": \"Kota Tangerang\"},\n",
    "          {\"store_id\": 45, \"store_name\": \"Jue Coffee Citra Raya\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 46, \"store_name\": \"Jue Coffee Lippo Karawaci\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 47, \"store_name\": \"Jue Coffee Daan Mogot Mall\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 48, \"store_name\": \"Jue Coffee Puri Kembangan\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 49, \"store_name\": \"Jue Coffee Green Lake City\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 50, \"store_name\": \"Jue Coffee Kedoya\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 51, \"store_name\": \"Jue Coffee Roxy Mas\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 52, \"store_name\": \"Jue Coffee Cempaka Putih\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 53, \"store_name\": \"Jue Coffee Senen\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 54, \"store_name\": \"Jue Coffee Menteng\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 55, \"store_name\": \"Jue Coffee Matraman\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 56, \"store_name\": \"Jue Coffee Pramuka\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 57, \"store_name\": \"Jue Coffee Arion Mall\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 58, \"store_name\": \"Jue Coffee Buaran Plaza\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 59, \"store_name\": \"Jue Coffee Klender\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 60, \"store_name\": \"Jue Coffee Pondok Kopi\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 61, \"store_name\": \"Jue Coffee Duren Sawit\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 62, \"store_name\": \"Jue Coffee Kramat Jati\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 63, \"store_name\": \"Jue Coffee Cawang\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 64, \"store_name\": \"Jue Coffee Halim Perdanakusuma\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 65, \"store_name\": \"Jue Coffee Kalimalang\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 66, \"store_name\": \"Jue Coffee Jatiwaringin\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 67, \"store_name\": \"Jue Coffee Pondok Gede\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 68, \"store_name\": \"Jue Coffee Galaxy Bekasi\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 69, \"store_name\": \"Jue Coffee Grand Galaxy Park\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 70, \"store_name\": \"Jue Coffee Summarecon Mall Bekasi\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 71, \"store_name\": \"Jue Coffee Metropolitan Mall Bekasi\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 72, \"store_name\": \"Jue Coffee Mega Bekasi Hypermall\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 73, \"store_name\": \"Jue Coffee Trans Studio Mall Cibubur\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 74, \"store_name\": \"Jue Coffee Cibubur Junction\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 75, \"store_name\": \"Jue Coffee Margonda Raya\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 76, \"store_name\": \"Jue Coffee Margo City\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 77, \"store_name\": \"Jue Coffee Depok Town Square\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 78, \"store_name\": \"Jue Coffee Cinere Bellevue Mall\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 79, \"store_name\": \"Jue Coffee Sawangan\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 80, \"store_name\": \"Jue Coffee Bojongsari\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 81, \"store_name\": \"Jue Coffee Cimanggis\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 82, \"store_name\": \"Jue Coffee Stasiun Depok Baru\", \"city_name\": \"Kota Depok\"},\n",
    "          {\"store_id\": 83, \"store_name\": \"Jue Coffee Sentul City\", \"city_name\": \"Kabupaten Bogor\"},\n",
    "          {\"store_id\": 84, \"store_name\": \"Jue Coffee Botani Square\", \"city_name\": \"Kota Bogor\"},\n",
    "          {\"store_id\": 85, \"store_name\": \"Jue Coffee Pajajaran Bogor\", \"city_name\": \"Kota Bogor\"},\n",
    "          {\"store_id\": 86, \"store_name\": \"Jue Coffee Stasiun Bogor\", \"city_name\": \"Kota Bogor\"},\n",
    "          {\"store_id\": 87, \"store_name\": \"Jue Coffee Yasmin Bogor\", \"city_name\": \"Kota Bogor\"},\n",
    "          {\"store_id\": 88, \"store_name\": \"Jue Coffee Ciawi\", \"city_name\": \"Kabupaten Bogor\"},\n",
    "          {\"store_id\": 89, \"store_name\": \"Jue Coffee Cibinong City Mall\", \"city_name\": \"Kabupaten Bogor\"},\n",
    "          {\"store_id\": 90, \"store_name\": \"Jue Coffee Gunung Putri\", \"city_name\": \"Kabupaten Bogor\"},\n",
    "          {\"store_id\": 91, \"store_name\": \"Jue Coffee BSD Green Office Park\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 92, \"store_name\": \"Jue Coffee Foresta Business Loft\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 93, \"store_name\": \"Jue Coffee Fatmawati\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 94, \"store_name\": \"Jue Coffee Ampera\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 95, \"store_name\": \"Jue Coffee Radio Dalam\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 96, \"store_name\": \"Jue Coffee Cipete\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 97, \"store_name\": \"Jue Coffee Kebon Jeruk\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 98, \"store_name\": \"Jue Coffee Tanjung Duren\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 99, \"store_name\": \"Jue Coffee Mangga Besar\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 100, \"store_name\": \"Jue Coffee Gajah Mada\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 101, \"store_name\": \"Jue Coffee Pasar Baru\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 102, \"store_name\": \"Jue Coffee Glodok\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 103, \"store_name\": \"Jue Coffee Sunter\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 104, \"store_name\": \"Jue Coffee Danau Sunter\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 105, \"store_name\": \"Jue Coffee Kelapa Gading Boulevard\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 106, \"store_name\": \"Jue Coffee Harapan Indah\", \"city_name\": \"Kota Bekasi\"},\n",
    "          {\"store_id\": 107, \"store_name\": \"Jue Coffee Kemayoran\", \"city_name\": \"Kota Jakarta Pusat\"},\n",
    "          {\"store_id\": 108, \"store_name\": \"Jue Coffee PIK 2\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 109, \"store_name\": \"Jue Coffee BSD City\", \"city_name\": \"Kota Tangerang Selatan\"},\n",
    "          {\"store_id\": 110, \"store_name\": \"Jue Coffee Karang Tengah\", \"city_name\": \"Kota Tangerang\"},\n",
    "          {\"store_id\": 111, \"store_name\": \"Jue Coffee Ciledug\", \"city_name\": \"Kota Tangerang\"},\n",
    "          {\"store_id\": 112, \"store_name\": \"Jue Coffee Legok\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 113, \"store_name\": \"Jue Coffee Tigaraksa\", \"city_name\": \"Kabupaten Tangerang\"},\n",
    "          {\"store_id\": 114, \"store_name\": \"Jue Coffee Cibinong\", \"city_name\": \"Kabupaten Bogor\"},\n",
    "          {\"store_id\": 115, \"store_name\": \"Jue Coffee Ciomas\", \"city_name\": \"Kabupaten Bogor\"},\n",
    "          {\"store_id\": 116, \"store_name\": \"Jue Coffee Sukabumi Utara\", \"city_name\": \"Kota Jakarta Barat\"},\n",
    "          {\"store_id\": 117, \"store_name\": \"Jue Coffee Kalibata City\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 118, \"store_name\": \"Jue Coffee Tebet Raya\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 119, \"store_name\": \"Jue Coffee Pondok Ranggon\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 120, \"store_name\": \"Jue Coffee Cipayung\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 121, \"store_name\": \"Jue Coffee Kebayoran Lama\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 122, \"store_name\": \"Jue Coffee Pasar Minggu\", \"city_name\": \"Kota Jakarta Selatan\"},\n",
    "          {\"store_id\": 123, \"store_name\": \"Jue Coffee Jatinegara\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 124, \"store_name\": \"Jue Coffee Pulogadung\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 125, \"store_name\": \"Jue Coffee Cakung\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 126, \"store_name\": \"Jue Coffee Rawamangun\", \"city_name\": \"Kota Jakarta Timur\"},\n",
    "          {\"store_id\": 127, \"store_name\": \"Jue Coffee Tanjung Priok\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 128, \"store_name\": \"Jue Coffee Koja\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 129, \"store_name\": \"Jue Coffee Semper\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 130, \"store_name\": \"Jue Coffee Ancol\", \"city_name\": \"Kota Jakarta Utara\"},\n",
    "          {\"store_id\": 131, \"store_name\": \"Jue Coffee Pademangan\", \"city_name\": \"Kota Jakarta Utara\"}\n",
    "    ]\n",
    "    return pl.DataFrame(store_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d8f2769-cac7-4de8-be93-44d99b792acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_categories_data() -> pl.DataFrame:\n",
    "    print(\"Getting static categories data...\")\n",
    "    categories_data = [\n",
    "        {\"category_id\": 1, \"category_name\": \"Coffee\"},\n",
    "        {\"category_id\": 2, \"category_name\": \"Non-Coffee\"},\n",
    "        {\"category_id\": 3, \"category_name\": \"Snacks\"},\n",
    "        {\"category_id\": 4, \"category_name\": \"Pastries & Cakes\"},\n",
    "        {\"category_id\": 5, \"category_name\": \"Breakfast Menu\"},\n",
    "        {\"category_id\": 6, \"category_name\": \"Lunch & Dinner\"},\n",
    "        {\"category_id\": 7, \"category_name\": \"Desserts\"},\n",
    "        {\"category_id\": 8, \"category_name\": \"Merchandise\"},\n",
    "        {\"category_id\": 9, \"category_name\": \"Brewing Equipment\"},\n",
    "        {\"category_id\": 10, \"category_name\": \"Packaged Beans\"}\n",
    "    ]\n",
    "    return pl.DataFrame(categories_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc70a69-fcb9-4918-8e7d-cd2f9c3f533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_data() -> pl.DataFrame:\n",
    "    print(\"Getting static products data...\")\n",
    "    products_data = [\n",
    "    {\"product_id\": 101, \"product_name\": \"Kopi Telur Tradisional\", \"category_id\": 1, \"unit_price\": 18000, \"base_price\": 13320},\n",
    "    {\"product_id\": 102, \"product_name\": \"Kopi Kelapa Khas Vietnam\", \"category_id\": 1, \"unit_price\": 22000, \"base_price\": 14960},\n",
    "    {\"product_id\": 103, \"product_name\": \"Kopi Vietnam Drip Original\", \"category_id\": 1, \"unit_price\": 20000, \"base_price\": 13600},\n",
    "    {\"product_id\": 104, \"product_name\": \"Kopi Butter Gurih\", \"category_id\": 1, \"unit_price\": 19000, \"base_price\": 12350},\n",
    "    {\"product_id\": 105, \"product_name\": \"Kopi Susu Kampung Kental Manis\", \"category_id\": 1, \"unit_price\": 15000, \"base_price\": 10800},\n",
    "    {\"product_id\": 106, \"product_name\": \"Kopi Coklat Spesial\", \"category_id\": 1, \"unit_price\": 21000, \"base_price\": 15750},\n",
    "    {\"product_id\": 107, \"product_name\": \"Es Kopi Susu Aren\", \"category_id\": 1, \"unit_price\": 23000, \"base_price\": 16100},\n",
    "    {\"product_id\": 108, \"product_name\": \"Es Kopi Hitam Dingin\", \"category_id\": 1, \"unit_price\": 16000, \"base_price\": 11040},\n",
    "    {\"product_id\": 109, \"product_name\": \"Es Kopi Hitam Lemon Segar\", \"category_id\": 1, \"unit_price\": 18000, \"base_price\": 12600},\n",
    "    {\"product_id\": 110, \"product_name\": \"Drip Bag Coffee Lokal Blend\", \"category_id\": 1, \"unit_price\": 25000, \"base_price\": 17250},\n",
    "    {\"product_id\": 111, \"product_name\": \"Espresso Shot\", \"category_id\": 1, \"unit_price\": 12000, \"base_price\": 8160},\n",
    "    {\"product_id\": 112, \"product_name\": \"Americano Panas\", \"category_id\": 1, \"unit_price\": 18000, \"base_price\": 12960},\n",
    "    {\"product_id\": 113, \"product_name\": \"Latte Panas\", \"category_id\": 1, \"unit_price\": 28000, \"base_price\": 18480},\n",
    "    {\"product_id\": 114, \"product_name\": \"Cappuccino Panas\", \"category_id\": 1, \"unit_price\": 28000, \"base_price\": 20160},\n",
    "    {\"product_id\": 115, \"product_name\": \"Macchiato Panas\", \"category_id\": 1, \"unit_price\": 28000, \"base_price\": 18200},\n",
    "    {\"product_id\": 116, \"product_name\": \"Mocha Panas\", \"category_id\": 1, \"unit_price\": 32000, \"base_price\": 22400},\n",
    "    {\"product_id\": 117, \"product_name\": \"Kopi Susu Regal\", \"category_id\": 1, \"unit_price\": 25000, \"base_price\": 16250},\n",
    "    {\"product_id\": 118, \"product_name\": \"Kopi Pandan Latte\", \"category_id\": 1, \"unit_price\": 27000, \"base_price\": 17550},\n",
    "    {\"product_id\": 119, \"product_name\": \"Ice Shaken Espresso\", \"category_id\": 1, \"unit_price\": 29000, \"base_price\": 21750},\n",
    "    {\"product_id\": 120, \"product_name\": \"Cold Brew Black\", \"category_id\": 1, \"unit_price\": 28000, \"base_price\": 19040},\n",
    "    {\"product_id\": 121, \"product_name\": \"Cold Brew White\", \"category_id\": 1, \"unit_price\": 32000, \"base_price\": 20800},\n",
    "    {\"product_id\": 122, \"product_name\": \"Affogato\", \"category_id\": 1, \"unit_price\": 30000, \"base_price\": 19500},\n",
    "    {\"product_id\": 123, \"product_name\": \"Manual Brew V60\", \"category_id\": 1, \"unit_price\": 35000, \"base_price\": 22750},\n",
    "    {\"product_id\": 124, \"product_name\": \"Manual Brew Aeropress\", \"category_id\": 1, \"unit_price\": 35000, \"base_price\": 26250},\n",
    "    {\"product_id\": 125, \"product_name\": \"Filter Coffee Seasonal\", \"category_id\": 1, \"unit_price\": 38000, \"base_price\": 24700},\n",
    "    {\"product_id\": 126, \"product_name\": \"Kopi Hitam Gula Aren\", \"category_id\": 1, \"unit_price\": 17000, \"base_price\": 12750},\n",
    "    {\"product_id\": 127, \"product_name\": \"Kopi Susu Caramel\", \"category_id\": 1, \"unit_price\": 26000, \"base_price\": 18200},\n",
    "    {\"product_id\": 128, \"product_name\": \"Kopi Hazelnut Latte\", \"category_id\": 1, \"unit_price\": 26000, \"base_price\": 17680},\n",
    "    {\"product_id\": 129, \"product_name\": \"Kopi Vanila Latte\", \"category_id\": 1, \"unit_price\": 26000, \"base_price\": 18460},\n",
    "    {\"product_id\": 130, \"product_name\": \"Jue Coffee Signature Latte\", \"category_id\": 1, \"unit_price\": 30000, \"base_price\": 20400},\n",
    "\n",
    "    {\"product_id\": 201, \"product_name\": \"Matcha Latte Premium\", \"category_id\": 2, \"unit_price\": 38000, \"base_price\": 26600},\n",
    "    {\"product_id\": 202, \"product_name\": \"Pure Chocolate Dingin\", \"category_id\": 2, \"unit_price\": 40000, \"base_price\": 26000},\n",
    "    {\"product_id\": 203, \"product_name\": \"Lemon Tea Segar\", \"category_id\": 2, \"unit_price\": 25000, \"base_price\": 17500},\n",
    "    {\"product_id\": 204, \"product_name\": \"Red Velvet Latte Creamy\", \"category_id\": 2, \"unit_price\": 39000, \"base_price\": 25350},\n",
    "    {\"product_id\": 205, \"product_name\": \"Thai Tea Original\", \"category_id\": 2, \"unit_price\": 28000, \"base_price\": 21000},\n",
    "    {\"product_id\": 206, \"product_name\": \"Green Tea Latte\", \"category_id\": 2, \"unit_price\": 36000, \"base_price\": 23400},\n",
    "    {\"product_id\": 207, \"product_name\": \"Taro Latte\", \"category_id\": 2, \"unit_price\": 37000, \"base_price\": 27380},\n",
    "    {\"product_id\": 208, \"product_name\": \"Strawberry Milkshake\", \"category_id\": 2, \"unit_price\": 35000, \"base_price\": 24500},\n",
    "    {\"product_id\": 209, \"product_name\": \"Cookies & Cream Frappe\", \"category_id\": 2, \"unit_price\": 42000, \"base_price\": 27300},\n",
    "    {\"product_id\": 210, \"product_name\": \"Virgin Mojito\", \"category_id\": 2, \"unit_price\": 33000, \"base_price\": 22440},\n",
    "    {\"product_id\": 211, \"product_name\": \"Lychee Tea\", \"category_id\": 2, \"unit_price\": 29000, \"base_price\": 20000},\n",
    "    {\"product_id\": 212, \"product_name\": \"Peach Tea\", \"category_id\": 2, \"unit_price\": 29000, \"base_price\": 18850},\n",
    "    {\"product_id\": 213, \"product_name\": \"Hot Chocolate Marshmallow\", \"category_id\": 2, \"unit_price\": 35000, \"base_price\": 22750},\n",
    "    {\"product_id\": 214, \"product_name\": \"Chai Latte\", \"category_id\": 2, \"unit_price\": 34000, \"base_price\": 25160},\n",
    "    {\"product_id\": 215, \"product_name\": \"Susu Regal\", \"category_id\": 2, \"unit_price\": 28000, \"base_price\": 19600},\n",
    "    {\"product_id\": 216, \"product_name\": \"Orange Juice Fresh\", \"category_id\": 2, \"unit_price\": 30000, \"base_price\": 21000},\n",
    "    {\"product_id\": 217, \"product_name\": \"Jus Alpukat\", \"category_id\": 2, \"unit_price\": 32000, \"base_price\": 20800},\n",
    "    {\"product_id\": 218, \"product_name\": \"Mineral Water\", \"category_id\": 2, \"unit_price\": 10000, \"base_price\": 6800},\n",
    "    {\"product_id\": 219, \"product_name\": \"Sparkling Water\", \"category_id\": 2, \"unit_price\": 15000, \"base_price\": 9900},\n",
    "    {\"product_id\": 220, \"product_name\": \"Ginger Ale\", \"category_id\": 2, \"unit_price\": 20000, \"base_price\": 14000},\n",
    "\n",
    "    {\"product_id\": 301, \"product_name\": \"French Fries Original\", \"category_id\": 3, \"unit_price\": 25000, \"base_price\": 18000},\n",
    "    {\"product_id\": 302, \"product_name\": \"Chicken Nugget\", \"category_id\": 3, \"unit_price\": 28000, \"base_price\": 19600},\n",
    "    {\"product_id\": 303, \"product_name\": \"Mini Spring Rolls\", \"category_id\": 3, \"unit_price\": 26000, \"base_price\": 17420},\n",
    "    {\"product_id\": 304, \"product_name\": \"Samosa Ayam\", \"category_id\": 3, \"unit_price\": 27000, \"base_price\": 17550},\n",
    "    {\"product_id\": 305, \"product_name\": \"Edamame Rebus\", \"category_id\": 3, \"unit_price\": 22000, \"base_price\": 14300},\n",
    "    {\"product_id\": 306, \"product_name\": \"Crispy Mushroom\", \"category_id\": 3, \"unit_price\": 29000, \"base_price\": 18850},\n",
    "    {\"product_id\": 307, \"product_name\": \"Onion Rings\", \"category_id\": 3, \"unit_price\": 27000, \"base_price\": 19440},\n",
    "    {\"product_id\": 308, \"product_name\": \"Fish & Chips Bites\", \"category_id\": 3, \"unit_price\": 35000, \"base_price\": 22750},\n",
    "    {\"product_id\": 309, \"product_name\": \"Nachos Cheese\", \"category_id\": 3, \"unit_price\": 38000, \"base_price\": 24700},\n",
    "    {\"product_id\": 310, \"product_name\": \"Sweet Potato Fries\", \"category_id\": 3, \"unit_price\": 28000, \"base_price\": 18200},\n",
    "\n",
    "    {\"product_id\": 401, \"product_name\": \"Butter Croissant\", \"category_id\": 4, \"unit_price\": 28000, \"base_price\": 18200},\n",
    "    {\"product_id\": 402, \"product_name\": \"Chocolate Croissant\", \"category_id\": 4, \"unit_price\": 32000, \"base_price\": 20800},\n",
    "    {\"product_id\": 403, \"product_name\": \"Almond Croissant\", \"category_id\": 4, \"unit_price\": 35000, \"base_price\": 23450},\n",
    "    {\"product_id\": 404, \"product_name\": \"Pain Au Chocolat\", \"category_id\": 4, \"unit_price\": 30000, \"base_price\": 19500},\n",
    "    {\"product_id\": 405, \"product_name\": \"Cinnamon Roll\", \"category_id\": 4, \"unit_price\": 29000, \"base_price\": 21750},\n",
    "    {\"product_id\": 406, \"product_name\": \"Banana Bread Slice\", \"category_id\": 4, \"unit_price\": 25000, \"base_price\": 17000},\n",
    "    {\"product_id\": 407, \"product_name\": \"Red Velvet Cake Slice\", \"category_id\": 4, \"unit_price\": 45000, \"base_price\": 29250},\n",
    "    {\"product_id\": 408, \"product_name\": \"Chocolate Fudge Cake Slice\", \"category_id\": 4, \"unit_price\": 45000, \"base_price\": 31050},\n",
    "    {\"product_id\": 409, \"product_name\": \"Blueberry Cheesecake Slice\", \"category_id\": 4, \"unit_price\": 48000, \"base_price\": 31200},\n",
    "    {\"product_id\": 410, \"product_name\": \"Marble Cake Slice\", \"category_id\": 4, \"unit_price\": 38000, \"base_price\": 24700},\n",
    "    {\"product_id\": 411, \"product_name\": \"Scones with Jam & Cream\", \"category_id\": 4, \"unit_price\": 33000, \"base_price\": 22440},\n",
    "    {\"product_id\": 412, \"product_name\": \"Muffin Coklat Chip\", \"category_id\": 4, \"unit_price\": 27000, \"base_price\": 19170},\n",
    "    {\"product_id\": 413, \"product_name\": \"Muffin Blueberry\", \"category_id\": 4, \"unit_price\": 27000, \"base_price\": 17820},\n",
    "    {\"product_id\": 414, \"product_name\": \"Donat Gula\", \"category_id\": 4, \"unit_price\": 18000, \"base_price\": 12600},\n",
    "    {\"product_id\": 415, \"product_name\": \"Cookies Chocochips\", \"category_id\": 4, \"unit_price\": 22000, \"base_price\": 15400},\n",
    "\n",
    "    {\"product_id\": 501, \"product_name\": \"Classic Omelette\", \"category_id\": 5, \"unit_price\": 40000, \"base_price\": 26000},\n",
    "    {\"product_id\": 502, \"product_name\": \"Scrambled Eggs on Toast\", \"category_id\": 5, \"unit_price\": 42000, \"base_price\": 27300},\n",
    "    {\"product_id\": 503, \"product_name\": \"Avocado Toast with Poached Egg\", \"category_id\": 5, \"unit_price\": 55000, \"base_price\": 35750},\n",
    "    {\"product_id\": 504, \"product_name\": \"Pancakes with Maple Syrup\", \"category_id\": 5, \"unit_price\": 48000, \"base_price\": 31200},\n",
    "    {\"product_id\": 505, \"product_name\": \"Waffles with Berries\", \"category_id\": 5, \"unit_price\": 50000, \"base_price\": 32500},\n",
    "    {\"product_id\": 506, \"product_name\": \"Granola Bowl with Yogurt\", \"category_id\": 5, \"unit_price\": 45000, \"base_price\": 31050},\n",
    "    {\"product_id\": 507, \"product_name\": \"Fruit Platter Fresh\", \"category_id\": 5, \"unit_price\": 35000, \"base_price\": 22750},\n",
    "    {\"product_id\": 508, \"product_name\": \"Chicken Porridge\", \"category_id\": 5, \"unit_price\": 38000, \"base_price\": 27740},\n",
    "\n",
    "    {\"product_id\": 601, \"product_name\": \"Spaghetti Aglio Olio\", \"category_id\": 6, \"unit_price\": 65000, \"base_price\": 47450},\n",
    "    {\"product_id\": 602, \"product_name\": \"Chicken Carbonara Pasta\", \"category_id\": 6, \"unit_price\": 70000, \"base_price\": 45500},\n",
    "    {\"product_id\": 603, \"product_name\": \"Nasi Goreng Kampung Jue\", \"category_id\": 6, \"unit_price\": 58000, \"base_price\": 43500},\n",
    "    {\"product_id\": 604, \"product_name\": \"Mie Goreng Tek-Tek\", \"category_id\": 6, \"unit_price\": 55000, \"base_price\": 35750},\n",
    "    {\"product_id\": 605, \"product_name\": \"Caesar Salad with Grilled Chicken\", \"category_id\": 6, \"unit_price\": 60000, \"base_price\": 42000},\n",
    "    {\"product_id\": 606, \"product_name\": \"Chicken Katsu Curry Rice\", \"category_id\": 6, \"unit_price\": 75000, \"base_price\": 50250},\n",
    "    {\"product_id\": 607, \"product_name\": \"Crispy Dory with Tartar Sauce\", \"category_id\": 6, \"unit_price\": 72000, \"base_price\": 46800},\n",
    "    {\"product_id\": 608, \"product_name\": \"Club Sandwich Classic\", \"category_id\": 6, \"unit_price\": 55000, \"base_price\": 37950},\n",
    "    {\"product_id\": 609, \"product_name\": \"Beef Burger with Fries\", \"category_id\": 6, \"unit_price\": 80000, \"base_price\": 52800},\n",
    "    {\"product_id\": 610, \"product_name\": \"Grilled Salmon Steak\", \"category_id\": 6, \"unit_price\": 95000, \"base_price\": 61750},\n",
    "\n",
    "    {\"product_id\": 701, \"product_name\": \"Ice Cream Scoop (Vanilla)\", \"category_id\": 7, \"unit_price\": 20000, \"base_price\": 14000},\n",
    "    {\"product_id\": 702, \"product_name\": \"Ice Cream Scoop (Chocolate)\", \"category_id\": 7, \"unit_price\": 20000, \"base_price\": 13000},\n",
    "    {\"product_id\": 703, \"product_name\": \"Ice Cream Scoop (Strawberry)\", \"category_id\": 7, \"unit_price\": 20000, \"base_price\": 14000},\n",
    "    {\"product_id\": 704, \"product_name\": \"Jue Coffee Banana Split\", \"category_id\": 7, \"unit_price\": 40000, \"base_price\": 26000},\n",
    "    {\"product_id\": 705, \"product_name\": \"Molten Lava Cake with Ice Cream\", \"category_id\": 7, \"unit_price\": 50000, \"base_price\": 32500},\n",
    "    {\"product_id\": 706, \"product_name\": \"Panna Cotta Berries\", \"category_id\": 7, \"unit_price\": 45000, \"base_price\": 29250},\n",
    "    {\"product_id\": 707, \"product_name\": \"Tiramisu Klasik\", \"category_id\": 7, \"unit_price\": 48000, \"base_price\": 33600},\n",
    "        \n",
    "    {\"product_id\": 801, \"product_name\": \"Jue Coffee Tumbler (Small)\", \"category_id\": 8, \"unit_price\": 95000, \"base_price\": 61750},\n",
    "    {\"product_id\": 802, \"product_name\": \"Jue Coffee Tumbler (Large)\", \"category_id\": 8, \"unit_price\": 120000, \"base_price\": 78000},\n",
    "    {\"product_id\": 803, \"product_name\": \"Jue Coffee T-Shirt (Size M)\", \"category_id\": 8, \"unit_price\": 150000, \"base_price\": 97500},\n",
    "    {\"product_id\": 804, \"product_name\": \"Jue Coffee Tote Bag\", \"category_id\": 8, \"unit_price\": 80000, \"base_price\": 52000},\n",
    "    {\"product_id\": 805, \"product_name\": \"Jue Coffee Mug\", \"category_id\": 8, \"unit_price\": 75000, \"base_price\": 48750},\n",
    "\n",
    "    {\"product_id\": 901, \"product_name\": \"V60 Dripper (Size 01)\", \"category_id\": 9, \"unit_price\": 120000, \"base_price\": 78000},\n",
    "    {\"product_id\": 902, \"product_name\": \"Aeropress Kit\", \"category_id\": 9, \"unit_price\": 450000, \"base_price\": 315000},\n",
    "    {\"product_id\": 903, \"product_name\": \"French Press (350ml)\", \"category_id\": 9, \"unit_price\": 180000, \"base_price\": 126000},\n",
    "    {\"product_id\": 904, \"product_name\": \"Pour Over Kettle\", \"category_id\": 9, \"unit_price\": 300000, \"base_price\": 210000},\n",
    "    {\"product_id\": 905, \"product_name\": \"Manual Grinder\", \"category_id\": 9, \"unit_price\": 250000, \"base_price\": 162500},\n",
    "\n",
    "    {\"product_id\": 1001, \"product_name\": \"Jue Coffee House Blend (250g)\", \"category_id\": 10, \"unit_price\": 85000, \"base_price\": 58650},\n",
    "    {\"product_id\": 1002, \"product_name\": \"Single Origin Arabica Gayo (250g)\", \"category_id\": 10, \"unit_price\": 120000, \"base_price\": 84000},\n",
    "    {\"product_id\": 1003, \"product_name\": \"Single Origin Robusta Lampung (250g)\", \"category_id\": 10, \"unit_price\": 75000, \"base_price\": 48750},\n",
    "    {\"product_id\": 1004, \"product_name\": \"Decaf Blend (250g)\", \"category_id\": 10, \"unit_price\": 90000, \"base_price\": 60300},\n",
    "    {\"product_id\": 1005, \"product_name\": \"Kopi Susu Blend (500g)\", \"category_id\": 10, \"unit_price\": 150000, \"base_price\": 105000}\n",
    "\n",
    "    ]\n",
    "    return pl.DataFrame(products_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f991f8dd-b979-40c6-b06b-3712d326d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transactions_data(\n",
    "    num_rows: int,\n",
    "    stores_df: pl.DataFrame,\n",
    "    products_df: pl.DataFrame,\n",
    "    output_csv_path: str\n",
    "):\n",
    "    if os.path.exists(output_csv_path) and pl.read_csv(output_csv_path).shape[0] == num_rows:\n",
    "        print(f\"File '{output_csv_path}' already exists with {num_rows} records. Skipping transaction data generation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Generating {num_rows} transaction records with fluctuating sales...\")\n",
    "\n",
    "    store_ids = stores_df[\"store_id\"].to_list()\n",
    "    product_ids = products_df[\"product_id\"].to_list()\n",
    "    product_id_to_price = {row[\"product_id\"]: row[\"unit_price\"] for row in products_df.iter_rows(named=True)}\n",
    "    all_transactions_data = []\n",
    "\n",
    "    # --- Logika untuk fluktuasi data ---\n",
    "    daily_demand_multiplier = defaultdict(lambda: 1.0)\n",
    "    for day_of_week in [5, 6]:  # Sabtu (5) dan Minggu (6)\n",
    "        daily_demand_multiplier[day_of_week] = 1.5\n",
    "\n",
    "    # Simulasikan pola permintaan musiman (misalnya, hari libur)\n",
    "    peak_sales_dates = {\n",
    "        (START_TRANSACTION_DATE.date() + timedelta(days=d)): 2.0 for d in range(10, 15)\n",
    "    }\n",
    "\n",
    "    # Persiapan daftar tanggal dan bobot untuk sampling\n",
    "    dates_in_range = [START_TRANSACTION_DATE + timedelta(days=d) for d in range((END_TRANSACTION_DATE - START_TRANSACTION_DATE).days + 1)]\n",
    "    date_weights = []\n",
    "    for date in dates_in_range:\n",
    "        multiplier = daily_demand_multiplier[date.weekday()]\n",
    "        if date.date() in peak_sales_dates:\n",
    "            multiplier *= peak_sales_dates[date.date()]\n",
    "        date_weights.append(multiplier)\n",
    "    \n",
    "    # --- Akhir logika fluktuasi ---\n",
    "\n",
    "    for i in range(N_CHUNKS):\n",
    "        chunk_data = []\n",
    "        for _ in range(CHUNK_SIZE):\n",
    "            transaction_id = fake.uuid4()\n",
    "            \n",
    "            # Pilih tanggal secara acak dengan bobot\n",
    "            transaction_date = random.choices(dates_in_range, weights=date_weights, k=1)[0]\n",
    "\n",
    "            chosen_store_id = random.choice(store_ids)\n",
    "            customer_id = None\n",
    "            chosen_product_id = random.choice(product_ids)\n",
    "            unit_price = product_id_to_price[chosen_product_id]\n",
    "\n",
    "            quantity = random.choices([1, 2, 3, 4, 5], weights=[0.6, 0.2, 0.1, 0.05, 0.05])[0]\n",
    "            payment_method = random.choice(['Cash', 'QRIS', 'Ovo', 'Gopay', 'ShopeePay', 'DANA', 'Debit card', 'Credit card'])\n",
    "            total_price = quantity * unit_price\n",
    "\n",
    "            # Introduce price discrepancies\n",
    "            if random.random() < 0.1:\n",
    "                total_price = int(total_price * random.uniform(0.9, 1.1))\n",
    "\n",
    "            chunk_data.append({\n",
    "                \"transaction_id\": transaction_id,\n",
    "                # Ganti 'datetime' menjadi 'date'\n",
    "                \"date\": transaction_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"store_id\": chosen_store_id,\n",
    "                \"customer_id\": customer_id,\n",
    "                \"product_id\": chosen_product_id,\n",
    "                \"quantity\": quantity,\n",
    "                \"payment_method\": payment_method,\n",
    "                \"price\": total_price\n",
    "            })\n",
    "            \n",
    "        # Introduce duplicate transactions in a chunk\n",
    "        if i > 0 and random.random() < 0.1:\n",
    "            num_duplicates = random.randint(1, 5)\n",
    "            if len(all_transactions_data) > num_duplicates:\n",
    "                chunk_data.extend(random.sample(all_transactions_data, num_duplicates))\n",
    "\n",
    "        all_transactions_data.extend(chunk_data)\n",
    "\n",
    "    df_transactions = pl.DataFrame(all_transactions_data)\n",
    "    df_transactions.write_csv(output_csv_path)\n",
    "    print(f\"Transaction data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ab98af1-d3ea-42ad-a1ec-64f7f1ced320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'stores.csv' already exists. Loading existing data.\n",
      "File 'categories.csv' already exists. Loading existing data.\n",
      "File 'products.csv' already exists. Loading existing data.\n",
      "File 'transactions.csv' already exists with 1000000 records. Skipping transaction data generation.\n",
      "\n",
      "Total data generation and saving took 0.77 seconds for 1000000 transactions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_start_time = time.perf_counter()\n",
    "\n",
    "if not os.path.exists(FILE_PATH_STORES):\n",
    "    stores_df = generate_stores_data(N_GENERATED_STORES)\n",
    "    stores_df.write_csv(FILE_PATH_STORES)\n",
    "    print(f\"Stores data saved to {FILE_PATH_STORES}\")\n",
    "else:\n",
    "    print(f\"File '{FILE_PATH_STORES}' already exists. Loading existing data.\")\n",
    "    stores_df = pl.read_csv(FILE_PATH_STORES)\n",
    "\n",
    "if not os.path.exists(FILE_PATH_CATEGORIES):\n",
    "    categories_df = get_categories_data()\n",
    "    categories_df.write_csv(FILE_PATH_CATEGORIES)\n",
    "    print(f\"Categories data saved to {FILE_PATH_CATEGORIES}\")\n",
    "else:\n",
    "    print(f\"File '{FILE_PATH_CATEGORIES}' already exists. Loading existing data.\")\n",
    "    categories_df = pl.read_csv(FILE_PATH_CATEGORIES)\n",
    "\n",
    "if not os.path.exists(FILE_PATH_PRODUCTS):\n",
    "    products_df = get_products_data()\n",
    "    products_df.write_csv(FILE_PATH_PRODUCTS)\n",
    "    print(f\"Products data saved to {FILE_PATH_PRODUCTS}\")\n",
    "else:\n",
    "    print(f\"File '{FILE_PATH_PRODUCTS}' already exists. Loading existing data.\")\n",
    "    products_df = pl.read_csv(FILE_PATH_PRODUCTS)\n",
    "\n",
    "generate_transactions_data(N_ROWS_TRANSACTIONS, stores_df, products_df, FILE_PATH_TRANSACTIONS)\n",
    " \n",
    "total_stop_time = time.perf_counter()\n",
    "elapsed_time = total_stop_time - total_start_time\n",
    "print(f\"\\nTotal data generation and saving took {elapsed_time:.2f} seconds for {N_ROWS_TRANSACTIONS} transactions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ab7280-2970-47fe-bc4f-9165e5b05bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/22 08:53:00 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>namespace</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>brz_coffeeshop_db</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>brz_hospital_db</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>coffeeshop</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gld_coffeeshop_db</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>gld_hospital_db</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>slv_coffeeshop_db</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>slv_hospital_db</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>coffeeshop_medalion</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------------------+\n",
       "|           namespace |\n",
       "+---------------------+\n",
       "|   brz_coffeeshop_db |\n",
       "|     brz_hospital_db |\n",
       "|          coffeeshop |\n",
       "|   gld_coffeeshop_db |\n",
       "|     gld_hospital_db |\n",
       "|   slv_coffeeshop_db |\n",
       "|     slv_hospital_db |\n",
       "| coffeeshop_medalion |\n",
       "+---------------------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SHOW DATABASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb4d63b-340c-4447-a98a-ce22643944e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create database if not exists coffeeshop;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9bdc37-6a75-456d-bc2f-860cb3f118dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/24 04:15:37 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "use coffeeshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13f79a1-2a7a-4fde-97c9-4713d2febe74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>namespace</th>\n",
       "            <th>tableName</th>\n",
       "            <th>isTemporary</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>coffeeshop</td>\n",
       "            <td>categories</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>coffeeshop</td>\n",
       "            <td>products</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>coffeeshop</td>\n",
       "            <td>stores</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>coffeeshop</td>\n",
       "            <td>transactions</td>\n",
       "            <td>False</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------+--------------+-------------+\n",
       "|  namespace |    tableName | isTemporary |\n",
       "+------------+--------------+-------------+\n",
       "| coffeeshop |   categories |       False |\n",
       "| coffeeshop |     products |       False |\n",
       "| coffeeshop |       stores |       False |\n",
       "| coffeeshop | transactions |       False |\n",
       "+------------+--------------+-------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "    \n",
    "show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ca0bbd-5e59-4947-99e8-473e03314a45",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o36.sql.\n: org.apache.iceberg.exceptions.ServiceFailureException: Server error: UncheckedSQLException: Failed to execute: DELETE FROM iceberg_tables WHERE catalog_name = ? AND table_namespace  = ? AND table_name = ? AND (iceberg_type = 'TABLE' OR iceberg_type IS NULL)\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:241)\n\tat org.apache.iceberg.rest.ErrorHandlers$TableErrorHandler.accept(ErrorHandlers.java:123)\n\tat org.apache.iceberg.rest.ErrorHandlers$TableErrorHandler.accept(ErrorHandlers.java:107)\n\tat org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:215)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:299)\n\tat org.apache.iceberg.rest.BaseHTTPClient.delete(BaseHTTPClient.java:55)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.dropTable(RESTSessionCatalog.java:304)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.dropTable(BaseSessionCatalog.java:112)\n\tat org.apache.iceberg.rest.RESTCatalog.dropTable(RESTCatalog.java:212)\n\tat org.apache.iceberg.CachingCatalog.dropTable(CachingCatalog.java:174)\n\tat org.apache.iceberg.spark.SparkCatalog.dropTableWithoutPurging(SparkCatalog.java:389)\n\tat org.apache.iceberg.spark.SparkCatalog.dropTable(SparkCatalog.java:354)\n\tat org.apache.spark.sql.execution.datasources.v2.DropTableExec.run(DropTableExec.scala:38)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msql\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdrop table stores\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ipython/profile_default/startup/00-prettytables.py:81\u001b[39m, in \u001b[36msql\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m     79\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _to_table(df, num_rows=args.limit)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _to_table(\u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/sql/session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o36.sql.\n: org.apache.iceberg.exceptions.ServiceFailureException: Server error: UncheckedSQLException: Failed to execute: DELETE FROM iceberg_tables WHERE catalog_name = ? AND table_namespace  = ? AND table_name = ? AND (iceberg_type = 'TABLE' OR iceberg_type IS NULL)\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:241)\n\tat org.apache.iceberg.rest.ErrorHandlers$TableErrorHandler.accept(ErrorHandlers.java:123)\n\tat org.apache.iceberg.rest.ErrorHandlers$TableErrorHandler.accept(ErrorHandlers.java:107)\n\tat org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:215)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:299)\n\tat org.apache.iceberg.rest.BaseHTTPClient.delete(BaseHTTPClient.java:55)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.dropTable(RESTSessionCatalog.java:304)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.dropTable(BaseSessionCatalog.java:112)\n\tat org.apache.iceberg.rest.RESTCatalog.dropTable(RESTCatalog.java:212)\n\tat org.apache.iceberg.CachingCatalog.dropTable(CachingCatalog.java:174)\n\tat org.apache.iceberg.spark.SparkCatalog.dropTableWithoutPurging(SparkCatalog.java:389)\n\tat org.apache.iceberg.spark.SparkCatalog.dropTable(SparkCatalog.java:354)\n\tat org.apache.spark.sql.execution.datasources.v2.DropTableExec.run(DropTableExec.scala:38)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "drop table stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e582e82-9c78-4d01-82af-470d3d8d8cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "drop table categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f2dab7-c3bb-42a8-9e01-05ae15762114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "drop table products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7521cffc-cb9f-49c4-bfa7-56cc200165bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "drop table transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf6557d5-0db0-43e4-8332-e449a56e0479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS categories (\n",
    "    category_id     STRING,         \n",
    "    category_name   STRING          \n",
    ")\n",
    "USING iceberg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bd9b74d-0db0-44c2-969c-0ec5317bfc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS categories (\n",
    "    category_id     STRING,         \n",
    "    category_name   STRING          \n",
    ")\n",
    "USING iceberg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10aacc2b-1b27-4d64-ae9c-3e6f4b30e2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS products (\n",
    "    product_id      STRING,        \n",
    "    product_name    STRING,\n",
    "    category_id     STRING,        \n",
    "    unit_price      STRING,        \n",
    "    base_price      STRING         \n",
    ")\n",
    "USING iceberg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b5a270f-f8b8-4553-91c9-8d2a94e4dbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS transactions (\n",
    "    transaction_id  STRING,\n",
    "    datetime        TIMESTAMP,     \n",
    "    store_id        STRING,        \n",
    "    customer_id     STRING,        \n",
    "    product_id      STRING,        \n",
    "    quantity        STRING,        \n",
    "    payment_method  STRING,        \n",
    "    price           STRING        \n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (days(datetime));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d76ee9-435a-4ce8-9519-8848f103a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for stores.csv:\n",
      "root\n",
      " |-- store_id: integer (nullable = true)\n",
      " |-- store_name: string (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      "\n",
      "First 5 rows from stores.csv:\n",
      "+--------+--------------------+--------------------+\n",
      "|store_id|          store_name|           city_name|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|Jue Coffee Kuning...|Kota Jakarta Selatan|\n",
      "|       2|Jue Coffee Grand ...|  Kota Jakarta Pusat|\n",
      "|       3|Jue Coffee Senaya...|  Kota Jakarta Pusat|\n",
      "|       4|Jue Coffee Pondok...|Kota Jakarta Selatan|\n",
      "|       5|Jue Coffee Gandar...|Kota Jakarta Selatan|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from stores.csv has been successfully loaded into the 'stores' Iceberg table.\n"
     ]
    }
   ],
   "source": [
    "stores_csv_path = \"stores.csv\" \n",
    "stores_df = spark.read.csv(stores_csv_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"Schema for {stores_csv_path}:\")\n",
    "stores_df.printSchema()\n",
    "print(f\"First 5 rows from {stores_csv_path}:\")\n",
    "stores_df.show(5)\n",
    "\n",
    "\n",
    "stores_df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"stores\")\n",
    "\n",
    "print(f\"Data from {stores_csv_path} has been successfully loaded into the 'stores' Iceberg table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f903e2e8-5c7b-46fd-bbee-948455691974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for categories.csv:\n",
      "root\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- category_name: string (nullable = true)\n",
      "\n",
      "First 5 rows from categories.csv:\n",
      "+-----------+----------------+\n",
      "|category_id|   category_name|\n",
      "+-----------+----------------+\n",
      "|          1|          Coffee|\n",
      "|          2|      Non-Coffee|\n",
      "|          3|          Snacks|\n",
      "|          4|Pastries & Cakes|\n",
      "|          5|  Breakfast Menu|\n",
      "+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Data from categories.csv has been successfully loaded into the 'categories' Iceberg table.\n"
     ]
    }
   ],
   "source": [
    "# Membaca data categories.csv\n",
    "categories_csv_path = \"categories.csv\" \n",
    "categories_df = spark.read.csv(categories_csv_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"Schema for {categories_csv_path}:\")\n",
    "categories_df.printSchema()\n",
    "print(f\"First 5 rows from {categories_csv_path}:\")\n",
    "categories_df.show(5)\n",
    "\n",
    "# Menulis data ke tabel Iceberg 'categories'\n",
    "categories_df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"categories\")\n",
    "\n",
    "print(f\"Data from {categories_csv_path} has been successfully loaded into the 'categories' Iceberg table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4857a5a-9cc5-4a27-b645-3b3c507652a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema for products.csv:\n",
      "root\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- unit_price: integer (nullable = true)\n",
      " |-- base_price: integer (nullable = true)\n",
      "\n",
      "First 5 rows from products.csv:\n",
      "+----------+------------------------------+-----------+----------+----------+\n",
      "|product_id|product_name                  |category_id|unit_price|base_price|\n",
      "+----------+------------------------------+-----------+----------+----------+\n",
      "|101       |Kopi Telur Tradisional        |1          |18000     |13320     |\n",
      "|102       |Kopi Kelapa Khas Vietnam      |1          |22000     |14960     |\n",
      "|103       |Kopi Vietnam Drip Original    |1          |20000     |13600     |\n",
      "|104       |Kopi Butter Gurih             |1          |19000     |12350     |\n",
      "|105       |Kopi Susu Kampung Kental Manis|1          |15000     |10800     |\n",
      "+----------+------------------------------+-----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Data from products.csv has been successfully loaded into the 'products' Iceberg table.\n"
     ]
    }
   ],
   "source": [
    "# Membaca data products.csv\n",
    "products_csv_path = \"products.csv\" # Sesuaikan path jika berbeda\n",
    "products_df = spark.read.csv(products_csv_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"Schema for {products_csv_path}:\")\n",
    "products_df.printSchema()\n",
    "print(f\"First 5 rows from {products_csv_path}:\")\n",
    "products_df.show(5, truncate=False) # truncate=False untuk melihat nama produk yang panjang\n",
    "\n",
    "# Menulis data ke tabel Iceberg 'products'\n",
    "products_df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"products\")\n",
    "\n",
    "print(f\"Data from {products_csv_path} has been successfully loaded into the 'products' Iceberg table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da58d8ce-912b-4d13-9417-ba2205ca6c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Schema for transactions.csv:\n",
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- store_id: integer (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n",
      "First 5 rows from transactions.csv:\n",
      "+------------------------------------+----------+--------+-----------+----------+--------+--------------+-----+\n",
      "|transaction_id                      |date      |store_id|customer_id|product_id|quantity|payment_method|price|\n",
      "+------------------------------------+----------+--------+-----------+----------+--------+--------------+-----+\n",
      "|bdd640fb-0667-4ad1-9c80-317fa3b1799d|2023-07-01|71      |NULL       |202       |1       |Debit card    |40000|\n",
      "|1a3d1fa7-bc89-40a9-a3b8-c1e9392456de|2023-07-01|23      |NULL       |501       |1       |DANA          |40000|\n",
      "|17fc695a-07a0-4a6e-8822-e8f36c031199|2023-07-01|56      |NULL       |130       |1       |QRIS          |30000|\n",
      "|8fadc1a6-06cb-4fb3-9a1d-e644815ef6d1|2023-07-01|51      |NULL       |609       |1       |DANA          |80000|\n",
      "|6b65a6a4-8b81-48f6-b38a-088ca65ed389|2023-07-01|57      |NULL       |308       |1       |Ovo           |35000|\n",
      "+------------------------------------+----------+--------+-----------+----------+--------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Schema after casting date for transactions.csv:\n",
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- store_id: integer (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/22 09:00:27 ERROR Executor: Exception in task 5.0 in stage 17.0 (TID 127)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 2.0 in stage 17.0 (TID 124)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 6.0 in stage 17.0 (TID 128)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 15.0 in stage 17.0 (TID 137)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 3.0 in stage 17.0 (TID 125)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 8.0 in stage 17.0 (TID 130)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 14.0 in stage 17.0 (TID 136)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 13.0 in stage 17.0 (TID 135)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 7.0 in stage 17.0 (TID 129)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 12.0 in stage 17.0 (TID 134)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 4.0 in stage 17.0 (TID 126)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 10.0 in stage 17.0 (TID 132)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 1.0 in stage 17.0 (TID 123)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 0.0 in stage 17.0 (TID 122)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 11.0 in stage 17.0 (TID 133)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 ERROR Executor: Exception in task 9.0 in stage 17.0 (TID 131)\n",
      "org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "25/08/22 09:00:27 WARN TaskSetManager: Lost task 5.0 in stage 17.0 (TID 127) (f8cc73c689d8 executor driver): org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "25/08/22 09:00:27 ERROR TaskSetManager: Task 5 in stage 17.0 failed 1 times; aborting job\n",
      "25/08/22 09:00:27 ERROR OverwriteByExpressionExec: Data source write support IcebergBatchWrite(table=minilake.coffeeshop.transactions, format=PARQUET) is aborting.\n",
      "25/08/22 09:00:27 WARN SparkWrite: Skipping cleanup of written files\n",
      "25/08/22 09:00:27 ERROR OverwriteByExpressionExec: Data source write support IcebergBatchWrite(table=minilake.coffeeshop.transactions, format=PARQUET) aborted.\n",
      "25/08/22 09:00:27 ERROR Utils: Aborting task\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 17.0 failed 1 times, most recent failure: Lost task 5.0 in stage 17.0 (TID 127) (f8cc73c689d8 executor driver): org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:390)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:364)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:248)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run(WriteToDataSourceV2Exec.scala:342)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run$(WriteToDataSourceV2Exec.scala:341)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:248)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:587)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable(WriteToDataSourceV2Exec.scala:579)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable$(WriteToDataSourceV2Exec.scala:572)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:186)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:221)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:645)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:575)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n",
      "\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n",
      "\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n",
      "\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n",
      "\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n",
      "\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n",
      "\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n",
      "\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n",
      "\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n",
      "\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n",
      "\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\t... 1 more\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o176.saveAsTable.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 17.0 failed 1 times, most recent failure: Lost task 5.0 in stage 17.0 (TID 127) (f8cc73c689d8 executor driver): org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:390)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:364)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:248)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run(WriteToDataSourceV2Exec.scala:342)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run$(WriteToDataSourceV2Exec.scala:341)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:248)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:587)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable(WriteToDataSourceV2Exec.scala:579)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable$(WriteToDataSourceV2Exec.scala:572)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:186)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:221)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:645)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:575)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m transactions_df.printSchema()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Menulis data ke tabel Iceberg 'transactions'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtransactions_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miceberg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moverwrite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtransactions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransactions_csv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has been successfully loaded into the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtransactions\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Iceberg table.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/sql/readwriter.py:1586\u001b[39m, in \u001b[36mDataFrameWriter.saveAsTable\u001b[39m\u001b[34m(self, name, format, mode, partitionBy, **options)\u001b[39m\n\u001b[32m   1584\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1585\u001b[39m     \u001b[38;5;28mself\u001b[39m.format(\u001b[38;5;28mformat\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1586\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o176.saveAsTable.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 17.0 failed 1 times, most recent failure: Lost task 5.0 in stage 17.0 (TID 127) (f8cc73c689d8 executor driver): org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2898)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2834)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2833)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2833)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1253)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1253)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3102)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3036)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3025)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:995)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:390)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:364)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:248)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run(WriteToDataSourceV2Exec.scala:342)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run$(WriteToDataSourceV2Exec.scala:341)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:248)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.$anonfun$writeToTable$1(WriteToDataSourceV2Exec.scala:587)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1397)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable(WriteToDataSourceV2Exec.scala:579)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CreateTableAsSelectBaseExec.writeToTable$(WriteToDataSourceV2Exec.scala:572)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.writeToTable(WriteToDataSourceV2Exec.scala:186)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:221)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:645)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:575)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: org.apache.iceberg.exceptions.ValidationException: Cannot find source column for partition field: 1000: datetime_day: day(2)\n\tat org.apache.iceberg.exceptions.ValidationException.check(ValidationException.java:49)\n\tat org.apache.iceberg.PartitionSpec.checkCompatibility(PartitionSpec.java:636)\n\tat org.apache.iceberg.PartitionSpec$Builder.build(PartitionSpec.java:617)\n\tat org.apache.iceberg.UnboundPartitionSpec.bind(UnboundPartitionSpec.java:46)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:71)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$1(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.util.JsonUtil.parse(JsonUtil.java:104)\n\tat org.apache.iceberg.PartitionSpecParser.lambda$fromJson$2(PartitionSpecParser.java:88)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$14(BoundedLocalCache.java:2406)\n\tat java.base/java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1916)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:2404)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:2387)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:108)\n\tat org.apache.iceberg.shaded.com.github.benmanes.caffeine.cache.LocalManualCache.get(LocalManualCache.java:62)\n\tat org.apache.iceberg.PartitionSpecParser.fromJson(PartitionSpecParser.java:86)\n\tat org.apache.iceberg.SerializableTable.lambda$specs$1(SerializableTable.java:223)\n\tat java.base/java.util.HashMap.forEach(HashMap.java:1421)\n\tat org.apache.iceberg.SerializableTable.specs(SerializableTable.java:221)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:674)\n\tat org.apache.iceberg.spark.source.SparkWrite$WriterFactory.createWriter(SparkWrite.java:668)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:441)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:430)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:496)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:393)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:621)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:624)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Membaca data transactions.csv\n",
    "transactions_csv_path = \"transactions.csv\" # Sesuaikan path jika berbeda\n",
    "\n",
    "# 'inferSchema=True' akan mengenali kolom 'date' sebagai tipe data String.\n",
    "transactions_df = spark.read.csv(transactions_csv_path, header=True, inferSchema=True)\n",
    "\n",
    "print(f\"Original Schema for {transactions_csv_path}:\")\n",
    "transactions_df.printSchema()\n",
    "print(f\"First 5 rows from {transactions_csv_path}:\")\n",
    "transactions_df.show(5, truncate=False)\n",
    "\n",
    "# Konversi kolom 'date' ke tipe data Date atau Timestamp jika diperlukan\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "# Ubah 'datetime' menjadi 'date' di baris ini\n",
    "# Kita bisa langsung mengonversinya ke tipe Date, karena tidak ada komponen waktu\n",
    "transactions_df = transactions_df.withColumn(\"date\", to_date(col(\"date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "print(f\"\\nSchema after casting date for {transactions_csv_path}:\")\n",
    "transactions_df.printSchema()\n",
    "\n",
    "# Menulis data ke tabel Iceberg 'transactions'\n",
    "transactions_df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"transactions\")\n",
    "\n",
    "print(f\"Data from {transactions_csv_path} has been successfully loaded into the 'transactions' Iceberg table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21e62ea9-25cc-41a9-8172-f2742072285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Di Spark SQL, hapus tabel yang ada\n",
    "spark.sql(\"DROP TABLE IF EXISTS transactions;\")\n",
    "\n",
    "# Kemudian, jalankan kembali kode PySpark Anda\n",
    "transactions_df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4134bf25-0aa1-43cd-a027-d4ad07c0f5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>category_id</th>\n",
       "            <th>category_name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>Coffee</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>Non-Coffee</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>Snacks</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4</td>\n",
       "            <td>Pastries &amp; Cakes</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5</td>\n",
       "            <td>Breakfast Menu</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6</td>\n",
       "            <td>Lunch &amp; Dinner</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7</td>\n",
       "            <td>Desserts</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8</td>\n",
       "            <td>Merchandise</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>9</td>\n",
       "            <td>Brewing Equipment</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>10</td>\n",
       "            <td>Packaged Beans</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------------+-------------------+\n",
       "| category_id |     category_name |\n",
       "+-------------+-------------------+\n",
       "|           1 |            Coffee |\n",
       "|           2 |        Non-Coffee |\n",
       "|           3 |            Snacks |\n",
       "|           4 |  Pastries & Cakes |\n",
       "|           5 |    Breakfast Menu |\n",
       "|           6 |    Lunch & Dinner |\n",
       "|           7 |          Desserts |\n",
       "|           8 |       Merchandise |\n",
       "|           9 | Brewing Equipment |\n",
       "|          10 |    Packaged Beans |\n",
       "+-------------+-------------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select * from categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6125e8a8-ea11-4274-9de9-b1783762508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>store_id</th>\n",
       "            <th>store_name</th>\n",
       "            <th>city_name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1</td>\n",
       "            <td>Jue Coffee Kuningan City</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2</td>\n",
       "            <td>Jue Coffee Grand Indonesia</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3</td>\n",
       "            <td>Jue Coffee Senayan City</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4</td>\n",
       "            <td>Jue Coffee Pondok Indah Mall</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5</td>\n",
       "            <td>Jue Coffee Gandaria City</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6</td>\n",
       "            <td>Jue Coffee Pacific Place</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7</td>\n",
       "            <td>Jue Coffee Kota Kasablanka</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8</td>\n",
       "            <td>Jue Coffee Lotte Avenue</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>9</td>\n",
       "            <td>Jue Coffee Plaza Senayan</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>10</td>\n",
       "            <td>Jue Coffee Sarinah Thamrin</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11</td>\n",
       "            <td>Jue Coffee FX Sudirman</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>12</td>\n",
       "            <td>Jue Coffee Central Park</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>13</td>\n",
       "            <td>Jue Coffee Taman Anggrek</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14</td>\n",
       "            <td>Jue Coffee Puri Indah Mall</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>15</td>\n",
       "            <td>Jue Coffee Mall Kelapa Gading</td>\n",
       "            <td>Kota Jakarta Utara</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>16</td>\n",
       "            <td>Jue Coffee Emporium Pluit</td>\n",
       "            <td>Kota Jakarta Utara</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>17</td>\n",
       "            <td>Jue Coffee PIK Avenue</td>\n",
       "            <td>Kota Jakarta Utara</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>18</td>\n",
       "            <td>Jue Coffee Mall Artha Gading</td>\n",
       "            <td>Kota Jakarta Utara</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>19</td>\n",
       "            <td>Jue Coffee One PM</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>20</td>\n",
       "            <td>Jue Coffee SCBD</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>21</td>\n",
       "            <td>Jue Coffee Kemang Village</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>22</td>\n",
       "            <td>Jue Coffee Cilandak Town Square</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>23</td>\n",
       "            <td>Jue Coffee Pejaten Village</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>24</td>\n",
       "            <td>Jue Coffee Bintaro XChange</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>25</td>\n",
       "            <td>Jue Coffee Transpark Bintaro</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>26</td>\n",
       "            <td>Jue Coffee The Breeze BSD</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>27</td>\n",
       "            <td>Jue Coffee Summarecon Mall Serpong</td>\n",
       "            <td>Kabupaten Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>28</td>\n",
       "            <td>Jue Coffee Living World Alam Sutera</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>29</td>\n",
       "            <td>Jue Coffee Supermal Karawaci</td>\n",
       "            <td>Kabupaten Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>30</td>\n",
       "            <td>Jue Coffee Tangcity Mall</td>\n",
       "            <td>Kota Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>31</td>\n",
       "            <td>Jue Coffee AEON Mall BSD</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>32</td>\n",
       "            <td>Jue Coffee IKEA Alam Sutera</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>33</td>\n",
       "            <td>Jue Coffee Teras Kota BSD</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>34</td>\n",
       "            <td>Jue Coffee Ciputat Raya</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>35</td>\n",
       "            <td>Jue Coffee Pamulang</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>36</td>\n",
       "            <td>Jue Coffee ITC BSD</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>37</td>\n",
       "            <td>Jue Coffee Pasar Modern BSD</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>38</td>\n",
       "            <td>Jue Coffee Gading Serpong</td>\n",
       "            <td>Kabupaten Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>39</td>\n",
       "            <td>Jue Coffee Mall @ Alam Sutera</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>40</td>\n",
       "            <td>Jue Coffee Cikokol</td>\n",
       "            <td>Kota Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>41</td>\n",
       "            <td>Jue Coffee Graha Raya</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>42</td>\n",
       "            <td>Jue Coffee Modernland Tangerang</td>\n",
       "            <td>Kota Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>43</td>\n",
       "            <td>Jue Coffee Alam Sutera Boulevard</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>44</td>\n",
       "            <td>Jue Coffee Stasiun Tangerang</td>\n",
       "            <td>Kota Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>45</td>\n",
       "            <td>Jue Coffee Citra Raya</td>\n",
       "            <td>Kabupaten Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>46</td>\n",
       "            <td>Jue Coffee Lippo Karawaci</td>\n",
       "            <td>Kabupaten Tangerang</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>47</td>\n",
       "            <td>Jue Coffee Daan Mogot Mall</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>48</td>\n",
       "            <td>Jue Coffee Puri Kembangan</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>49</td>\n",
       "            <td>Jue Coffee Green Lake City</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>50</td>\n",
       "            <td>Jue Coffee Kedoya</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>51</td>\n",
       "            <td>Jue Coffee Roxy Mas</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>52</td>\n",
       "            <td>Jue Coffee Cempaka Putih</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>53</td>\n",
       "            <td>Jue Coffee Senen</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>54</td>\n",
       "            <td>Jue Coffee Menteng</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>55</td>\n",
       "            <td>Jue Coffee Matraman</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>56</td>\n",
       "            <td>Jue Coffee Pramuka</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>57</td>\n",
       "            <td>Jue Coffee Arion Mall</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>58</td>\n",
       "            <td>Jue Coffee Buaran Plaza</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>59</td>\n",
       "            <td>Jue Coffee Klender</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>60</td>\n",
       "            <td>Jue Coffee Pondok Kopi</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>61</td>\n",
       "            <td>Jue Coffee Duren Sawit</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>62</td>\n",
       "            <td>Jue Coffee Kramat Jati</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>63</td>\n",
       "            <td>Jue Coffee Cawang</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>64</td>\n",
       "            <td>Jue Coffee Halim Perdanakusuma</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>65</td>\n",
       "            <td>Jue Coffee Kalimalang</td>\n",
       "            <td>Kota Jakarta Timur</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>66</td>\n",
       "            <td>Jue Coffee Jatiwaringin</td>\n",
       "            <td>Kota Bekasi</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>67</td>\n",
       "            <td>Jue Coffee Pondok Gede</td>\n",
       "            <td>Kota Bekasi</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>68</td>\n",
       "            <td>Jue Coffee Galaxy Bekasi</td>\n",
       "            <td>Kota Bekasi</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>69</td>\n",
       "            <td>Jue Coffee Grand Galaxy Park</td>\n",
       "            <td>Kota Bekasi</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>70</td>\n",
       "            <td>Jue Coffee Summarecon Mall Bekasi</td>\n",
       "            <td>Kota Bekasi</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>71</td>\n",
       "            <td>Jue Coffee Metropolitan Mall Bekasi</td>\n",
       "            <td>Kota Bekasi</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>72</td>\n",
       "            <td>Jue Coffee Mega Bekasi Hypermall</td>\n",
       "            <td>Kota Bekasi</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>73</td>\n",
       "            <td>Jue Coffee Trans Studio Mall Cibubur</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>74</td>\n",
       "            <td>Jue Coffee Cibubur Junction</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>75</td>\n",
       "            <td>Jue Coffee Margonda Raya</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>76</td>\n",
       "            <td>Jue Coffee Margo City</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>77</td>\n",
       "            <td>Jue Coffee Depok Town Square</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>78</td>\n",
       "            <td>Jue Coffee Cinere Bellevue Mall</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>79</td>\n",
       "            <td>Jue Coffee Sawangan</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>80</td>\n",
       "            <td>Jue Coffee Bojongsari</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>81</td>\n",
       "            <td>Jue Coffee Cimanggis</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>82</td>\n",
       "            <td>Jue Coffee Stasiun Depok Baru</td>\n",
       "            <td>Kota Depok</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>83</td>\n",
       "            <td>Jue Coffee Sentul City</td>\n",
       "            <td>Kabupaten Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>84</td>\n",
       "            <td>Jue Coffee Botani Square</td>\n",
       "            <td>Kota Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>85</td>\n",
       "            <td>Jue Coffee Pajajaran Bogor</td>\n",
       "            <td>Kota Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>86</td>\n",
       "            <td>Jue Coffee Stasiun Bogor</td>\n",
       "            <td>Kota Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>87</td>\n",
       "            <td>Jue Coffee Yasmin Bogor</td>\n",
       "            <td>Kota Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>88</td>\n",
       "            <td>Jue Coffee Ciawi</td>\n",
       "            <td>Kabupaten Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>89</td>\n",
       "            <td>Jue Coffee Cibinong City Mall</td>\n",
       "            <td>Kabupaten Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>90</td>\n",
       "            <td>Jue Coffee Gunung Putri</td>\n",
       "            <td>Kabupaten Bogor</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>91</td>\n",
       "            <td>Jue Coffee BSD Green Office Park</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>92</td>\n",
       "            <td>Jue Coffee Foresta Business Loft</td>\n",
       "            <td>Kota Tangerang Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>93</td>\n",
       "            <td>Jue Coffee Fatmawati</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>94</td>\n",
       "            <td>Jue Coffee Ampera</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>95</td>\n",
       "            <td>Jue Coffee Radio Dalam</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>96</td>\n",
       "            <td>Jue Coffee Cipete</td>\n",
       "            <td>Kota Jakarta Selatan</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>97</td>\n",
       "            <td>Jue Coffee Kebon Jeruk</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>98</td>\n",
       "            <td>Jue Coffee Tanjung Duren</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>99</td>\n",
       "            <td>Jue Coffee Mangga Besar</td>\n",
       "            <td>Kota Jakarta Barat</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>100</td>\n",
       "            <td>Jue Coffee Gajah Mada</td>\n",
       "            <td>Kota Jakarta Pusat</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------+--------------------------------------+------------------------+\n",
       "| store_id |                           store_name |              city_name |\n",
       "+----------+--------------------------------------+------------------------+\n",
       "|        1 |             Jue Coffee Kuningan City |   Kota Jakarta Selatan |\n",
       "|        2 |           Jue Coffee Grand Indonesia |     Kota Jakarta Pusat |\n",
       "|        3 |              Jue Coffee Senayan City |     Kota Jakarta Pusat |\n",
       "|        4 |         Jue Coffee Pondok Indah Mall |   Kota Jakarta Selatan |\n",
       "|        5 |             Jue Coffee Gandaria City |   Kota Jakarta Selatan |\n",
       "|        6 |             Jue Coffee Pacific Place |   Kota Jakarta Selatan |\n",
       "|        7 |           Jue Coffee Kota Kasablanka |   Kota Jakarta Selatan |\n",
       "|        8 |              Jue Coffee Lotte Avenue |   Kota Jakarta Selatan |\n",
       "|        9 |             Jue Coffee Plaza Senayan |     Kota Jakarta Pusat |\n",
       "|       10 |           Jue Coffee Sarinah Thamrin |     Kota Jakarta Pusat |\n",
       "|       11 |               Jue Coffee FX Sudirman |     Kota Jakarta Pusat |\n",
       "|       12 |              Jue Coffee Central Park |     Kota Jakarta Barat |\n",
       "|       13 |             Jue Coffee Taman Anggrek |     Kota Jakarta Barat |\n",
       "|       14 |           Jue Coffee Puri Indah Mall |     Kota Jakarta Barat |\n",
       "|       15 |        Jue Coffee Mall Kelapa Gading |     Kota Jakarta Utara |\n",
       "|       16 |            Jue Coffee Emporium Pluit |     Kota Jakarta Utara |\n",
       "|       17 |                Jue Coffee PIK Avenue |     Kota Jakarta Utara |\n",
       "|       18 |         Jue Coffee Mall Artha Gading |     Kota Jakarta Utara |\n",
       "|       19 |                    Jue Coffee One PM |   Kota Jakarta Selatan |\n",
       "|       20 |                      Jue Coffee SCBD |   Kota Jakarta Selatan |\n",
       "|       21 |            Jue Coffee Kemang Village |   Kota Jakarta Selatan |\n",
       "|       22 |      Jue Coffee Cilandak Town Square |   Kota Jakarta Selatan |\n",
       "|       23 |           Jue Coffee Pejaten Village |   Kota Jakarta Selatan |\n",
       "|       24 |           Jue Coffee Bintaro XChange | Kota Tangerang Selatan |\n",
       "|       25 |         Jue Coffee Transpark Bintaro | Kota Tangerang Selatan |\n",
       "|       26 |            Jue Coffee The Breeze BSD | Kota Tangerang Selatan |\n",
       "|       27 |   Jue Coffee Summarecon Mall Serpong |    Kabupaten Tangerang |\n",
       "|       28 |  Jue Coffee Living World Alam Sutera | Kota Tangerang Selatan |\n",
       "|       29 |         Jue Coffee Supermal Karawaci |    Kabupaten Tangerang |\n",
       "|       30 |             Jue Coffee Tangcity Mall |         Kota Tangerang |\n",
       "|       31 |             Jue Coffee AEON Mall BSD | Kota Tangerang Selatan |\n",
       "|       32 |          Jue Coffee IKEA Alam Sutera | Kota Tangerang Selatan |\n",
       "|       33 |            Jue Coffee Teras Kota BSD | Kota Tangerang Selatan |\n",
       "|       34 |              Jue Coffee Ciputat Raya | Kota Tangerang Selatan |\n",
       "|       35 |                  Jue Coffee Pamulang | Kota Tangerang Selatan |\n",
       "|       36 |                   Jue Coffee ITC BSD | Kota Tangerang Selatan |\n",
       "|       37 |          Jue Coffee Pasar Modern BSD | Kota Tangerang Selatan |\n",
       "|       38 |            Jue Coffee Gading Serpong |    Kabupaten Tangerang |\n",
       "|       39 |        Jue Coffee Mall @ Alam Sutera | Kota Tangerang Selatan |\n",
       "|       40 |                   Jue Coffee Cikokol |         Kota Tangerang |\n",
       "|       41 |                Jue Coffee Graha Raya | Kota Tangerang Selatan |\n",
       "|       42 |      Jue Coffee Modernland Tangerang |         Kota Tangerang |\n",
       "|       43 |     Jue Coffee Alam Sutera Boulevard | Kota Tangerang Selatan |\n",
       "|       44 |         Jue Coffee Stasiun Tangerang |         Kota Tangerang |\n",
       "|       45 |                Jue Coffee Citra Raya |    Kabupaten Tangerang |\n",
       "|       46 |            Jue Coffee Lippo Karawaci |    Kabupaten Tangerang |\n",
       "|       47 |           Jue Coffee Daan Mogot Mall |     Kota Jakarta Barat |\n",
       "|       48 |            Jue Coffee Puri Kembangan |     Kota Jakarta Barat |\n",
       "|       49 |           Jue Coffee Green Lake City |     Kota Jakarta Barat |\n",
       "|       50 |                    Jue Coffee Kedoya |     Kota Jakarta Barat |\n",
       "|       51 |                  Jue Coffee Roxy Mas |     Kota Jakarta Pusat |\n",
       "|       52 |             Jue Coffee Cempaka Putih |     Kota Jakarta Pusat |\n",
       "|       53 |                     Jue Coffee Senen |     Kota Jakarta Pusat |\n",
       "|       54 |                   Jue Coffee Menteng |     Kota Jakarta Pusat |\n",
       "|       55 |                  Jue Coffee Matraman |     Kota Jakarta Timur |\n",
       "|       56 |                   Jue Coffee Pramuka |     Kota Jakarta Timur |\n",
       "|       57 |                Jue Coffee Arion Mall |     Kota Jakarta Timur |\n",
       "|       58 |              Jue Coffee Buaran Plaza |     Kota Jakarta Timur |\n",
       "|       59 |                   Jue Coffee Klender |     Kota Jakarta Timur |\n",
       "|       60 |               Jue Coffee Pondok Kopi |     Kota Jakarta Timur |\n",
       "|       61 |               Jue Coffee Duren Sawit |     Kota Jakarta Timur |\n",
       "|       62 |               Jue Coffee Kramat Jati |     Kota Jakarta Timur |\n",
       "|       63 |                    Jue Coffee Cawang |     Kota Jakarta Timur |\n",
       "|       64 |       Jue Coffee Halim Perdanakusuma |     Kota Jakarta Timur |\n",
       "|       65 |                Jue Coffee Kalimalang |     Kota Jakarta Timur |\n",
       "|       66 |              Jue Coffee Jatiwaringin |            Kota Bekasi |\n",
       "|       67 |               Jue Coffee Pondok Gede |            Kota Bekasi |\n",
       "|       68 |             Jue Coffee Galaxy Bekasi |            Kota Bekasi |\n",
       "|       69 |         Jue Coffee Grand Galaxy Park |            Kota Bekasi |\n",
       "|       70 |    Jue Coffee Summarecon Mall Bekasi |            Kota Bekasi |\n",
       "|       71 |  Jue Coffee Metropolitan Mall Bekasi |            Kota Bekasi |\n",
       "|       72 |     Jue Coffee Mega Bekasi Hypermall |            Kota Bekasi |\n",
       "|       73 | Jue Coffee Trans Studio Mall Cibubur |             Kota Depok |\n",
       "|       74 |          Jue Coffee Cibubur Junction |             Kota Depok |\n",
       "|       75 |             Jue Coffee Margonda Raya |             Kota Depok |\n",
       "|       76 |                Jue Coffee Margo City |             Kota Depok |\n",
       "|       77 |         Jue Coffee Depok Town Square |             Kota Depok |\n",
       "|       78 |      Jue Coffee Cinere Bellevue Mall |             Kota Depok |\n",
       "|       79 |                  Jue Coffee Sawangan |             Kota Depok |\n",
       "|       80 |                Jue Coffee Bojongsari |             Kota Depok |\n",
       "|       81 |                 Jue Coffee Cimanggis |             Kota Depok |\n",
       "|       82 |        Jue Coffee Stasiun Depok Baru |             Kota Depok |\n",
       "|       83 |               Jue Coffee Sentul City |        Kabupaten Bogor |\n",
       "|       84 |             Jue Coffee Botani Square |             Kota Bogor |\n",
       "|       85 |           Jue Coffee Pajajaran Bogor |             Kota Bogor |\n",
       "|       86 |             Jue Coffee Stasiun Bogor |             Kota Bogor |\n",
       "|       87 |              Jue Coffee Yasmin Bogor |             Kota Bogor |\n",
       "|       88 |                     Jue Coffee Ciawi |        Kabupaten Bogor |\n",
       "|       89 |        Jue Coffee Cibinong City Mall |        Kabupaten Bogor |\n",
       "|       90 |              Jue Coffee Gunung Putri |        Kabupaten Bogor |\n",
       "|       91 |     Jue Coffee BSD Green Office Park | Kota Tangerang Selatan |\n",
       "|       92 |     Jue Coffee Foresta Business Loft | Kota Tangerang Selatan |\n",
       "|       93 |                 Jue Coffee Fatmawati |   Kota Jakarta Selatan |\n",
       "|       94 |                    Jue Coffee Ampera |   Kota Jakarta Selatan |\n",
       "|       95 |               Jue Coffee Radio Dalam |   Kota Jakarta Selatan |\n",
       "|       96 |                    Jue Coffee Cipete |   Kota Jakarta Selatan |\n",
       "|       97 |               Jue Coffee Kebon Jeruk |     Kota Jakarta Barat |\n",
       "|       98 |             Jue Coffee Tanjung Duren |     Kota Jakarta Barat |\n",
       "|       99 |              Jue Coffee Mangga Besar |     Kota Jakarta Barat |\n",
       "|      100 |                Jue Coffee Gajah Mada |     Kota Jakarta Pusat |\n",
       "+----------+--------------------------------------+------------------------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select * from stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a268058e-9314-4502-95f4-24f14e81735d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>product_id</th>\n",
       "            <th>product_name</th>\n",
       "            <th>category_id</th>\n",
       "            <th>unit_price</th>\n",
       "            <th>base_price</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>101</td>\n",
       "            <td>Kopi Telur Tradisional</td>\n",
       "            <td>1</td>\n",
       "            <td>18000</td>\n",
       "            <td>13320</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>102</td>\n",
       "            <td>Kopi Kelapa Khas Vietnam</td>\n",
       "            <td>1</td>\n",
       "            <td>22000</td>\n",
       "            <td>14960</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>103</td>\n",
       "            <td>Kopi Vietnam Drip Original</td>\n",
       "            <td>1</td>\n",
       "            <td>20000</td>\n",
       "            <td>13600</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>104</td>\n",
       "            <td>Kopi Butter Gurih</td>\n",
       "            <td>1</td>\n",
       "            <td>19000</td>\n",
       "            <td>12350</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>105</td>\n",
       "            <td>Kopi Susu Kampung Kental Manis</td>\n",
       "            <td>1</td>\n",
       "            <td>15000</td>\n",
       "            <td>10800</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>106</td>\n",
       "            <td>Kopi Coklat Spesial</td>\n",
       "            <td>1</td>\n",
       "            <td>21000</td>\n",
       "            <td>15750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>107</td>\n",
       "            <td>Es Kopi Susu Aren</td>\n",
       "            <td>1</td>\n",
       "            <td>23000</td>\n",
       "            <td>16100</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>108</td>\n",
       "            <td>Es Kopi Hitam Dingin</td>\n",
       "            <td>1</td>\n",
       "            <td>16000</td>\n",
       "            <td>11040</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>109</td>\n",
       "            <td>Es Kopi Hitam Lemon Segar</td>\n",
       "            <td>1</td>\n",
       "            <td>18000</td>\n",
       "            <td>12600</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>110</td>\n",
       "            <td>Drip Bag Coffee Lokal Blend</td>\n",
       "            <td>1</td>\n",
       "            <td>25000</td>\n",
       "            <td>17250</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>111</td>\n",
       "            <td>Espresso Shot</td>\n",
       "            <td>1</td>\n",
       "            <td>12000</td>\n",
       "            <td>8160</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>112</td>\n",
       "            <td>Americano Panas</td>\n",
       "            <td>1</td>\n",
       "            <td>18000</td>\n",
       "            <td>12960</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>113</td>\n",
       "            <td>Latte Panas</td>\n",
       "            <td>1</td>\n",
       "            <td>28000</td>\n",
       "            <td>18480</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>114</td>\n",
       "            <td>Cappuccino Panas</td>\n",
       "            <td>1</td>\n",
       "            <td>28000</td>\n",
       "            <td>20160</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>115</td>\n",
       "            <td>Macchiato Panas</td>\n",
       "            <td>1</td>\n",
       "            <td>28000</td>\n",
       "            <td>18200</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>116</td>\n",
       "            <td>Mocha Panas</td>\n",
       "            <td>1</td>\n",
       "            <td>32000</td>\n",
       "            <td>22400</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>117</td>\n",
       "            <td>Kopi Susu Regal</td>\n",
       "            <td>1</td>\n",
       "            <td>25000</td>\n",
       "            <td>16250</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>118</td>\n",
       "            <td>Kopi Pandan Latte</td>\n",
       "            <td>1</td>\n",
       "            <td>27000</td>\n",
       "            <td>17550</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>119</td>\n",
       "            <td>Ice Shaken Espresso</td>\n",
       "            <td>1</td>\n",
       "            <td>29000</td>\n",
       "            <td>21750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>120</td>\n",
       "            <td>Cold Brew Black</td>\n",
       "            <td>1</td>\n",
       "            <td>28000</td>\n",
       "            <td>19040</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>121</td>\n",
       "            <td>Cold Brew White</td>\n",
       "            <td>1</td>\n",
       "            <td>32000</td>\n",
       "            <td>20800</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>122</td>\n",
       "            <td>Affogato</td>\n",
       "            <td>1</td>\n",
       "            <td>30000</td>\n",
       "            <td>19500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>123</td>\n",
       "            <td>Manual Brew V60</td>\n",
       "            <td>1</td>\n",
       "            <td>35000</td>\n",
       "            <td>22750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>124</td>\n",
       "            <td>Manual Brew Aeropress</td>\n",
       "            <td>1</td>\n",
       "            <td>35000</td>\n",
       "            <td>26250</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>125</td>\n",
       "            <td>Filter Coffee Seasonal</td>\n",
       "            <td>1</td>\n",
       "            <td>38000</td>\n",
       "            <td>24700</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>126</td>\n",
       "            <td>Kopi Hitam Gula Aren</td>\n",
       "            <td>1</td>\n",
       "            <td>17000</td>\n",
       "            <td>12750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>127</td>\n",
       "            <td>Kopi Susu Caramel</td>\n",
       "            <td>1</td>\n",
       "            <td>26000</td>\n",
       "            <td>18200</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>128</td>\n",
       "            <td>Kopi Hazelnut Latte</td>\n",
       "            <td>1</td>\n",
       "            <td>26000</td>\n",
       "            <td>17680</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>129</td>\n",
       "            <td>Kopi Vanila Latte</td>\n",
       "            <td>1</td>\n",
       "            <td>26000</td>\n",
       "            <td>18460</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>130</td>\n",
       "            <td>Jue Coffee Signature Latte</td>\n",
       "            <td>1</td>\n",
       "            <td>30000</td>\n",
       "            <td>20400</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>201</td>\n",
       "            <td>Matcha Latte Premium</td>\n",
       "            <td>2</td>\n",
       "            <td>38000</td>\n",
       "            <td>26600</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>202</td>\n",
       "            <td>Pure Chocolate Dingin</td>\n",
       "            <td>2</td>\n",
       "            <td>40000</td>\n",
       "            <td>26000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>203</td>\n",
       "            <td>Lemon Tea Segar</td>\n",
       "            <td>2</td>\n",
       "            <td>25000</td>\n",
       "            <td>17500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>204</td>\n",
       "            <td>Red Velvet Latte Creamy</td>\n",
       "            <td>2</td>\n",
       "            <td>39000</td>\n",
       "            <td>25350</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>205</td>\n",
       "            <td>Thai Tea Original</td>\n",
       "            <td>2</td>\n",
       "            <td>28000</td>\n",
       "            <td>21000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>206</td>\n",
       "            <td>Green Tea Latte</td>\n",
       "            <td>2</td>\n",
       "            <td>36000</td>\n",
       "            <td>23400</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>207</td>\n",
       "            <td>Taro Latte</td>\n",
       "            <td>2</td>\n",
       "            <td>37000</td>\n",
       "            <td>27380</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>208</td>\n",
       "            <td>Strawberry Milkshake</td>\n",
       "            <td>2</td>\n",
       "            <td>35000</td>\n",
       "            <td>24500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>209</td>\n",
       "            <td>Cookies &amp; Cream Frappe</td>\n",
       "            <td>2</td>\n",
       "            <td>42000</td>\n",
       "            <td>27300</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>210</td>\n",
       "            <td>Virgin Mojito</td>\n",
       "            <td>2</td>\n",
       "            <td>33000</td>\n",
       "            <td>22440</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>211</td>\n",
       "            <td>Lychee Tea</td>\n",
       "            <td>2</td>\n",
       "            <td>29000</td>\n",
       "            <td>20000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>212</td>\n",
       "            <td>Peach Tea</td>\n",
       "            <td>2</td>\n",
       "            <td>29000</td>\n",
       "            <td>18850</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>213</td>\n",
       "            <td>Hot Chocolate Marshmallow</td>\n",
       "            <td>2</td>\n",
       "            <td>35000</td>\n",
       "            <td>22750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>214</td>\n",
       "            <td>Chai Latte</td>\n",
       "            <td>2</td>\n",
       "            <td>34000</td>\n",
       "            <td>25160</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>215</td>\n",
       "            <td>Susu Regal</td>\n",
       "            <td>2</td>\n",
       "            <td>28000</td>\n",
       "            <td>19600</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>216</td>\n",
       "            <td>Orange Juice Fresh</td>\n",
       "            <td>2</td>\n",
       "            <td>30000</td>\n",
       "            <td>21000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>217</td>\n",
       "            <td>Jus Alpukat</td>\n",
       "            <td>2</td>\n",
       "            <td>32000</td>\n",
       "            <td>20800</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>218</td>\n",
       "            <td>Mineral Water</td>\n",
       "            <td>2</td>\n",
       "            <td>10000</td>\n",
       "            <td>6800</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>219</td>\n",
       "            <td>Sparkling Water</td>\n",
       "            <td>2</td>\n",
       "            <td>15000</td>\n",
       "            <td>9900</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>220</td>\n",
       "            <td>Ginger Ale</td>\n",
       "            <td>2</td>\n",
       "            <td>20000</td>\n",
       "            <td>14000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>301</td>\n",
       "            <td>French Fries Original</td>\n",
       "            <td>3</td>\n",
       "            <td>25000</td>\n",
       "            <td>18000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>302</td>\n",
       "            <td>Chicken Nugget</td>\n",
       "            <td>3</td>\n",
       "            <td>28000</td>\n",
       "            <td>19600</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>303</td>\n",
       "            <td>Mini Spring Rolls</td>\n",
       "            <td>3</td>\n",
       "            <td>26000</td>\n",
       "            <td>17420</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>304</td>\n",
       "            <td>Samosa Ayam</td>\n",
       "            <td>3</td>\n",
       "            <td>27000</td>\n",
       "            <td>17550</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>305</td>\n",
       "            <td>Edamame Rebus</td>\n",
       "            <td>3</td>\n",
       "            <td>22000</td>\n",
       "            <td>14300</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>306</td>\n",
       "            <td>Crispy Mushroom</td>\n",
       "            <td>3</td>\n",
       "            <td>29000</td>\n",
       "            <td>18850</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>307</td>\n",
       "            <td>Onion Rings</td>\n",
       "            <td>3</td>\n",
       "            <td>27000</td>\n",
       "            <td>19440</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>308</td>\n",
       "            <td>Fish &amp; Chips Bites</td>\n",
       "            <td>3</td>\n",
       "            <td>35000</td>\n",
       "            <td>22750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>309</td>\n",
       "            <td>Nachos Cheese</td>\n",
       "            <td>3</td>\n",
       "            <td>38000</td>\n",
       "            <td>24700</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>310</td>\n",
       "            <td>Sweet Potato Fries</td>\n",
       "            <td>3</td>\n",
       "            <td>28000</td>\n",
       "            <td>18200</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>401</td>\n",
       "            <td>Butter Croissant</td>\n",
       "            <td>4</td>\n",
       "            <td>28000</td>\n",
       "            <td>18200</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>402</td>\n",
       "            <td>Chocolate Croissant</td>\n",
       "            <td>4</td>\n",
       "            <td>32000</td>\n",
       "            <td>20800</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>403</td>\n",
       "            <td>Almond Croissant</td>\n",
       "            <td>4</td>\n",
       "            <td>35000</td>\n",
       "            <td>23450</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>404</td>\n",
       "            <td>Pain Au Chocolat</td>\n",
       "            <td>4</td>\n",
       "            <td>30000</td>\n",
       "            <td>19500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>405</td>\n",
       "            <td>Cinnamon Roll</td>\n",
       "            <td>4</td>\n",
       "            <td>29000</td>\n",
       "            <td>21750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>406</td>\n",
       "            <td>Banana Bread Slice</td>\n",
       "            <td>4</td>\n",
       "            <td>25000</td>\n",
       "            <td>17000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>407</td>\n",
       "            <td>Red Velvet Cake Slice</td>\n",
       "            <td>4</td>\n",
       "            <td>45000</td>\n",
       "            <td>29250</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>408</td>\n",
       "            <td>Chocolate Fudge Cake Slice</td>\n",
       "            <td>4</td>\n",
       "            <td>45000</td>\n",
       "            <td>31050</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>409</td>\n",
       "            <td>Blueberry Cheesecake Slice</td>\n",
       "            <td>4</td>\n",
       "            <td>48000</td>\n",
       "            <td>31200</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>410</td>\n",
       "            <td>Marble Cake Slice</td>\n",
       "            <td>4</td>\n",
       "            <td>38000</td>\n",
       "            <td>24700</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>411</td>\n",
       "            <td>Scones with Jam &amp; Cream</td>\n",
       "            <td>4</td>\n",
       "            <td>33000</td>\n",
       "            <td>22440</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>412</td>\n",
       "            <td>Muffin Coklat Chip</td>\n",
       "            <td>4</td>\n",
       "            <td>27000</td>\n",
       "            <td>19170</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>413</td>\n",
       "            <td>Muffin Blueberry</td>\n",
       "            <td>4</td>\n",
       "            <td>27000</td>\n",
       "            <td>17820</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>414</td>\n",
       "            <td>Donat Gula</td>\n",
       "            <td>4</td>\n",
       "            <td>18000</td>\n",
       "            <td>12600</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>415</td>\n",
       "            <td>Cookies Chocochips</td>\n",
       "            <td>4</td>\n",
       "            <td>22000</td>\n",
       "            <td>15400</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>501</td>\n",
       "            <td>Classic Omelette</td>\n",
       "            <td>5</td>\n",
       "            <td>40000</td>\n",
       "            <td>26000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>502</td>\n",
       "            <td>Scrambled Eggs on Toast</td>\n",
       "            <td>5</td>\n",
       "            <td>42000</td>\n",
       "            <td>27300</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>503</td>\n",
       "            <td>Avocado Toast with Poached Egg</td>\n",
       "            <td>5</td>\n",
       "            <td>55000</td>\n",
       "            <td>35750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>504</td>\n",
       "            <td>Pancakes with Maple Syrup</td>\n",
       "            <td>5</td>\n",
       "            <td>48000</td>\n",
       "            <td>31200</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>505</td>\n",
       "            <td>Waffles with Berries</td>\n",
       "            <td>5</td>\n",
       "            <td>50000</td>\n",
       "            <td>32500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>506</td>\n",
       "            <td>Granola Bowl with Yogurt</td>\n",
       "            <td>5</td>\n",
       "            <td>45000</td>\n",
       "            <td>31050</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>507</td>\n",
       "            <td>Fruit Platter Fresh</td>\n",
       "            <td>5</td>\n",
       "            <td>35000</td>\n",
       "            <td>22750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>508</td>\n",
       "            <td>Chicken Porridge</td>\n",
       "            <td>5</td>\n",
       "            <td>38000</td>\n",
       "            <td>27740</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>601</td>\n",
       "            <td>Spaghetti Aglio Olio</td>\n",
       "            <td>6</td>\n",
       "            <td>65000</td>\n",
       "            <td>47450</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>602</td>\n",
       "            <td>Chicken Carbonara Pasta</td>\n",
       "            <td>6</td>\n",
       "            <td>70000</td>\n",
       "            <td>45500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>603</td>\n",
       "            <td>Nasi Goreng Kampung Jue</td>\n",
       "            <td>6</td>\n",
       "            <td>58000</td>\n",
       "            <td>43500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>604</td>\n",
       "            <td>Mie Goreng Tek-Tek</td>\n",
       "            <td>6</td>\n",
       "            <td>55000</td>\n",
       "            <td>35750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>605</td>\n",
       "            <td>Caesar Salad with Grilled Chicken</td>\n",
       "            <td>6</td>\n",
       "            <td>60000</td>\n",
       "            <td>42000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>606</td>\n",
       "            <td>Chicken Katsu Curry Rice</td>\n",
       "            <td>6</td>\n",
       "            <td>75000</td>\n",
       "            <td>50250</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>607</td>\n",
       "            <td>Crispy Dory with Tartar Sauce</td>\n",
       "            <td>6</td>\n",
       "            <td>72000</td>\n",
       "            <td>46800</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>608</td>\n",
       "            <td>Club Sandwich Classic</td>\n",
       "            <td>6</td>\n",
       "            <td>55000</td>\n",
       "            <td>37950</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>609</td>\n",
       "            <td>Beef Burger with Fries</td>\n",
       "            <td>6</td>\n",
       "            <td>80000</td>\n",
       "            <td>52800</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>610</td>\n",
       "            <td>Grilled Salmon Steak</td>\n",
       "            <td>6</td>\n",
       "            <td>95000</td>\n",
       "            <td>61750</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>701</td>\n",
       "            <td>Ice Cream Scoop (Vanilla)</td>\n",
       "            <td>7</td>\n",
       "            <td>20000</td>\n",
       "            <td>14000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>702</td>\n",
       "            <td>Ice Cream Scoop (Chocolate)</td>\n",
       "            <td>7</td>\n",
       "            <td>20000</td>\n",
       "            <td>13000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>703</td>\n",
       "            <td>Ice Cream Scoop (Strawberry)</td>\n",
       "            <td>7</td>\n",
       "            <td>20000</td>\n",
       "            <td>14000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>704</td>\n",
       "            <td>Jue Coffee Banana Split</td>\n",
       "            <td>7</td>\n",
       "            <td>40000</td>\n",
       "            <td>26000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>705</td>\n",
       "            <td>Molten Lava Cake with Ice Cream</td>\n",
       "            <td>7</td>\n",
       "            <td>50000</td>\n",
       "            <td>32500</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>706</td>\n",
       "            <td>Panna Cotta Berries</td>\n",
       "            <td>7</td>\n",
       "            <td>45000</td>\n",
       "            <td>29250</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>707</td>\n",
       "            <td>Tiramisu Klasik</td>\n",
       "            <td>7</td>\n",
       "            <td>48000</td>\n",
       "            <td>33600</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+------------+-----------------------------------+-------------+------------+------------+\n",
       "| product_id |                      product_name | category_id | unit_price | base_price |\n",
       "+------------+-----------------------------------+-------------+------------+------------+\n",
       "|        101 |            Kopi Telur Tradisional |           1 |      18000 |      13320 |\n",
       "|        102 |          Kopi Kelapa Khas Vietnam |           1 |      22000 |      14960 |\n",
       "|        103 |        Kopi Vietnam Drip Original |           1 |      20000 |      13600 |\n",
       "|        104 |                 Kopi Butter Gurih |           1 |      19000 |      12350 |\n",
       "|        105 |    Kopi Susu Kampung Kental Manis |           1 |      15000 |      10800 |\n",
       "|        106 |               Kopi Coklat Spesial |           1 |      21000 |      15750 |\n",
       "|        107 |                 Es Kopi Susu Aren |           1 |      23000 |      16100 |\n",
       "|        108 |              Es Kopi Hitam Dingin |           1 |      16000 |      11040 |\n",
       "|        109 |         Es Kopi Hitam Lemon Segar |           1 |      18000 |      12600 |\n",
       "|        110 |       Drip Bag Coffee Lokal Blend |           1 |      25000 |      17250 |\n",
       "|        111 |                     Espresso Shot |           1 |      12000 |       8160 |\n",
       "|        112 |                   Americano Panas |           1 |      18000 |      12960 |\n",
       "|        113 |                       Latte Panas |           1 |      28000 |      18480 |\n",
       "|        114 |                  Cappuccino Panas |           1 |      28000 |      20160 |\n",
       "|        115 |                   Macchiato Panas |           1 |      28000 |      18200 |\n",
       "|        116 |                       Mocha Panas |           1 |      32000 |      22400 |\n",
       "|        117 |                   Kopi Susu Regal |           1 |      25000 |      16250 |\n",
       "|        118 |                 Kopi Pandan Latte |           1 |      27000 |      17550 |\n",
       "|        119 |               Ice Shaken Espresso |           1 |      29000 |      21750 |\n",
       "|        120 |                   Cold Brew Black |           1 |      28000 |      19040 |\n",
       "|        121 |                   Cold Brew White |           1 |      32000 |      20800 |\n",
       "|        122 |                          Affogato |           1 |      30000 |      19500 |\n",
       "|        123 |                   Manual Brew V60 |           1 |      35000 |      22750 |\n",
       "|        124 |             Manual Brew Aeropress |           1 |      35000 |      26250 |\n",
       "|        125 |            Filter Coffee Seasonal |           1 |      38000 |      24700 |\n",
       "|        126 |              Kopi Hitam Gula Aren |           1 |      17000 |      12750 |\n",
       "|        127 |                 Kopi Susu Caramel |           1 |      26000 |      18200 |\n",
       "|        128 |               Kopi Hazelnut Latte |           1 |      26000 |      17680 |\n",
       "|        129 |                 Kopi Vanila Latte |           1 |      26000 |      18460 |\n",
       "|        130 |        Jue Coffee Signature Latte |           1 |      30000 |      20400 |\n",
       "|        201 |              Matcha Latte Premium |           2 |      38000 |      26600 |\n",
       "|        202 |             Pure Chocolate Dingin |           2 |      40000 |      26000 |\n",
       "|        203 |                   Lemon Tea Segar |           2 |      25000 |      17500 |\n",
       "|        204 |           Red Velvet Latte Creamy |           2 |      39000 |      25350 |\n",
       "|        205 |                 Thai Tea Original |           2 |      28000 |      21000 |\n",
       "|        206 |                   Green Tea Latte |           2 |      36000 |      23400 |\n",
       "|        207 |                        Taro Latte |           2 |      37000 |      27380 |\n",
       "|        208 |              Strawberry Milkshake |           2 |      35000 |      24500 |\n",
       "|        209 |            Cookies & Cream Frappe |           2 |      42000 |      27300 |\n",
       "|        210 |                     Virgin Mojito |           2 |      33000 |      22440 |\n",
       "|        211 |                        Lychee Tea |           2 |      29000 |      20000 |\n",
       "|        212 |                         Peach Tea |           2 |      29000 |      18850 |\n",
       "|        213 |         Hot Chocolate Marshmallow |           2 |      35000 |      22750 |\n",
       "|        214 |                        Chai Latte |           2 |      34000 |      25160 |\n",
       "|        215 |                        Susu Regal |           2 |      28000 |      19600 |\n",
       "|        216 |                Orange Juice Fresh |           2 |      30000 |      21000 |\n",
       "|        217 |                       Jus Alpukat |           2 |      32000 |      20800 |\n",
       "|        218 |                     Mineral Water |           2 |      10000 |       6800 |\n",
       "|        219 |                   Sparkling Water |           2 |      15000 |       9900 |\n",
       "|        220 |                        Ginger Ale |           2 |      20000 |      14000 |\n",
       "|        301 |             French Fries Original |           3 |      25000 |      18000 |\n",
       "|        302 |                    Chicken Nugget |           3 |      28000 |      19600 |\n",
       "|        303 |                 Mini Spring Rolls |           3 |      26000 |      17420 |\n",
       "|        304 |                       Samosa Ayam |           3 |      27000 |      17550 |\n",
       "|        305 |                     Edamame Rebus |           3 |      22000 |      14300 |\n",
       "|        306 |                   Crispy Mushroom |           3 |      29000 |      18850 |\n",
       "|        307 |                       Onion Rings |           3 |      27000 |      19440 |\n",
       "|        308 |                Fish & Chips Bites |           3 |      35000 |      22750 |\n",
       "|        309 |                     Nachos Cheese |           3 |      38000 |      24700 |\n",
       "|        310 |                Sweet Potato Fries |           3 |      28000 |      18200 |\n",
       "|        401 |                  Butter Croissant |           4 |      28000 |      18200 |\n",
       "|        402 |               Chocolate Croissant |           4 |      32000 |      20800 |\n",
       "|        403 |                  Almond Croissant |           4 |      35000 |      23450 |\n",
       "|        404 |                  Pain Au Chocolat |           4 |      30000 |      19500 |\n",
       "|        405 |                     Cinnamon Roll |           4 |      29000 |      21750 |\n",
       "|        406 |                Banana Bread Slice |           4 |      25000 |      17000 |\n",
       "|        407 |             Red Velvet Cake Slice |           4 |      45000 |      29250 |\n",
       "|        408 |        Chocolate Fudge Cake Slice |           4 |      45000 |      31050 |\n",
       "|        409 |        Blueberry Cheesecake Slice |           4 |      48000 |      31200 |\n",
       "|        410 |                 Marble Cake Slice |           4 |      38000 |      24700 |\n",
       "|        411 |           Scones with Jam & Cream |           4 |      33000 |      22440 |\n",
       "|        412 |                Muffin Coklat Chip |           4 |      27000 |      19170 |\n",
       "|        413 |                  Muffin Blueberry |           4 |      27000 |      17820 |\n",
       "|        414 |                        Donat Gula |           4 |      18000 |      12600 |\n",
       "|        415 |                Cookies Chocochips |           4 |      22000 |      15400 |\n",
       "|        501 |                  Classic Omelette |           5 |      40000 |      26000 |\n",
       "|        502 |           Scrambled Eggs on Toast |           5 |      42000 |      27300 |\n",
       "|        503 |    Avocado Toast with Poached Egg |           5 |      55000 |      35750 |\n",
       "|        504 |         Pancakes with Maple Syrup |           5 |      48000 |      31200 |\n",
       "|        505 |              Waffles with Berries |           5 |      50000 |      32500 |\n",
       "|        506 |          Granola Bowl with Yogurt |           5 |      45000 |      31050 |\n",
       "|        507 |               Fruit Platter Fresh |           5 |      35000 |      22750 |\n",
       "|        508 |                  Chicken Porridge |           5 |      38000 |      27740 |\n",
       "|        601 |              Spaghetti Aglio Olio |           6 |      65000 |      47450 |\n",
       "|        602 |           Chicken Carbonara Pasta |           6 |      70000 |      45500 |\n",
       "|        603 |           Nasi Goreng Kampung Jue |           6 |      58000 |      43500 |\n",
       "|        604 |                Mie Goreng Tek-Tek |           6 |      55000 |      35750 |\n",
       "|        605 | Caesar Salad with Grilled Chicken |           6 |      60000 |      42000 |\n",
       "|        606 |          Chicken Katsu Curry Rice |           6 |      75000 |      50250 |\n",
       "|        607 |     Crispy Dory with Tartar Sauce |           6 |      72000 |      46800 |\n",
       "|        608 |             Club Sandwich Classic |           6 |      55000 |      37950 |\n",
       "|        609 |            Beef Burger with Fries |           6 |      80000 |      52800 |\n",
       "|        610 |              Grilled Salmon Steak |           6 |      95000 |      61750 |\n",
       "|        701 |         Ice Cream Scoop (Vanilla) |           7 |      20000 |      14000 |\n",
       "|        702 |       Ice Cream Scoop (Chocolate) |           7 |      20000 |      13000 |\n",
       "|        703 |      Ice Cream Scoop (Strawberry) |           7 |      20000 |      14000 |\n",
       "|        704 |           Jue Coffee Banana Split |           7 |      40000 |      26000 |\n",
       "|        705 |   Molten Lava Cake with Ice Cream |           7 |      50000 |      32500 |\n",
       "|        706 |               Panna Cotta Berries |           7 |      45000 |      29250 |\n",
       "|        707 |                   Tiramisu Klasik |           7 |      48000 |      33600 |\n",
       "+------------+-----------------------------------+-------------+------------+------------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select * from products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4867cf-b74b-4254-8341-983d0aafc000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>transaction_id</th>\n",
       "            <th>date</th>\n",
       "            <th>store_id</th>\n",
       "            <th>customer_id</th>\n",
       "            <th>product_id</th>\n",
       "            <th>quantity</th>\n",
       "            <th>payment_method</th>\n",
       "            <th>price</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>bdd640fb-0667-4ad1-9c80-317fa3b1799d</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>71</td>\n",
       "            <td>None</td>\n",
       "            <td>202</td>\n",
       "            <td>1</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>40000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1a3d1fa7-bc89-40a9-a3b8-c1e9392456de</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>23</td>\n",
       "            <td>None</td>\n",
       "            <td>501</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>40000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>17fc695a-07a0-4a6e-8822-e8f36c031199</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>56</td>\n",
       "            <td>None</td>\n",
       "            <td>130</td>\n",
       "            <td>1</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>30000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8fadc1a6-06cb-4fb3-9a1d-e644815ef6d1</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>51</td>\n",
       "            <td>None</td>\n",
       "            <td>609</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>80000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6b65a6a4-8b81-48f6-b38a-088ca65ed389</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>57</td>\n",
       "            <td>None</td>\n",
       "            <td>308</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>35000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>de8a774b-cf36-458b-8737-819096da1dac</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>2</td>\n",
       "            <td>None</td>\n",
       "            <td>705</td>\n",
       "            <td>1</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>50000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6c307511-b2b9-437a-a8df-6ec4ce4a2bbd</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>88</td>\n",
       "            <td>None</td>\n",
       "            <td>206</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>36000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>c37459ee-f50b-4a63-b71e-cd7b27cd8130</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>87</td>\n",
       "            <td>None</td>\n",
       "            <td>114</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5be6128e-18c2-4797-a142-ea7d17be3111</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>89</td>\n",
       "            <td>None</td>\n",
       "            <td>503</td>\n",
       "            <td>1</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>55000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bacfb3d0-0b1f-4163-8e9f-f57f43b7a3a6</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>118</td>\n",
       "            <td>None</td>\n",
       "            <td>409</td>\n",
       "            <td>2</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>96000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>60e7a113-ec1b-4ca1-b91e-1d4c1ff49b78</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>21</td>\n",
       "            <td>None</td>\n",
       "            <td>411</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>33000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>9e574f7a-a0ee-49ae-9453-dd324b0dbb41</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>93</td>\n",
       "            <td>None</td>\n",
       "            <td>414</td>\n",
       "            <td>2</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>36000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0bbb2599-11ce-4dd2-b45e-d1f03139d32c</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>59</td>\n",
       "            <td>None</td>\n",
       "            <td>706</td>\n",
       "            <td>5</td>\n",
       "            <td>Cash</td>\n",
       "            <td>225000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>daf61a26-146d-4f31-bc37-7a4c4a15544d</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>60</td>\n",
       "            <td>None</td>\n",
       "            <td>1001</td>\n",
       "            <td>2</td>\n",
       "            <td>Cash</td>\n",
       "            <td>170000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7412b293-4729-4739-a14f-f3d719db3ad0</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>94</td>\n",
       "            <td>None</td>\n",
       "            <td>121</td>\n",
       "            <td>2</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>64000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ab9099a4-35a2-40ae-9af3-05535ec42e08</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>69</td>\n",
       "            <td>None</td>\n",
       "            <td>607</td>\n",
       "            <td>4</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>288000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>12476f57-a5e5-45ab-aefc-fad8efc89849</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>44</td>\n",
       "            <td>None</td>\n",
       "            <td>409</td>\n",
       "            <td>1</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>48000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7656af72-29d4-4eef-beab-edcbbaa80dd4</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>98</td>\n",
       "            <td>None</td>\n",
       "            <td>205</td>\n",
       "            <td>1</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>b02b61c4-a3d7-4628-ace6-6fa2fd5166e6</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>57</td>\n",
       "            <td>None</td>\n",
       "            <td>605</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>60000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>c6a7ee39-c4b0-42cc-97c5-24a55304317f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>15</td>\n",
       "            <td>None</td>\n",
       "            <td>130</td>\n",
       "            <td>1</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>30000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>50c187fc-ce17-4b4e-8837-b8a3d261a7ab</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>103</td>\n",
       "            <td>None</td>\n",
       "            <td>205</td>\n",
       "            <td>2</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>56000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>f16287e4-e9c3-49e0-b602-f8ac10f1bc81</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>81</td>\n",
       "            <td>None</td>\n",
       "            <td>128</td>\n",
       "            <td>3</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>78000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>e27a984d-6548-41d0-bfcd-9eb1a7cad415</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>118</td>\n",
       "            <td>None</td>\n",
       "            <td>119</td>\n",
       "            <td>1</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>29000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>beb79919-3f22-4af8-a3be-d01d43cf2fde</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>68</td>\n",
       "            <td>None</td>\n",
       "            <td>703</td>\n",
       "            <td>5</td>\n",
       "            <td>DANA</td>\n",
       "            <td>100000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>956269f0-e5d7-4875-adad-d6c795a76d79</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>103</td>\n",
       "            <td>None</td>\n",
       "            <td>217</td>\n",
       "            <td>1</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>29505</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2369b584-ff5e-4ff0-bf50-bde4382567b8</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>131</td>\n",
       "            <td>None</td>\n",
       "            <td>404</td>\n",
       "            <td>1</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>30000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dc713d96-0c0f-4195-817a-f08a1745d6d8</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>29</td>\n",
       "            <td>None</td>\n",
       "            <td>120</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ae340454-cac5-468c-a8f4-9481a0a04dc4</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>109</td>\n",
       "            <td>None</td>\n",
       "            <td>502</td>\n",
       "            <td>1</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>42000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>988c24c9-61b1-4d22-a280-1c4510435a10</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>120</td>\n",
       "            <td>None</td>\n",
       "            <td>408</td>\n",
       "            <td>2</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>95069</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dc5c0eed-8da0-465b-b898-97b9405cacec</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>3</td>\n",
       "            <td>None</td>\n",
       "            <td>605</td>\n",
       "            <td>1</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>60000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>e2817efd-ae84-4217-9d53-434bb88139b9</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>69</td>\n",
       "            <td>None</td>\n",
       "            <td>706</td>\n",
       "            <td>1</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>45000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4b22d308-1c8e-4ee9-9715-bd6fa4161293</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>112</td>\n",
       "            <td>None</td>\n",
       "            <td>121</td>\n",
       "            <td>2</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>59361</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>b8db0672-f42d-47cc-80d4-af5974273ca3</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>68</td>\n",
       "            <td>None</td>\n",
       "            <td>405</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>29000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>e9a1fa6f-81f7-4d1c-adbc-2134c30ff46e</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>28</td>\n",
       "            <td>None</td>\n",
       "            <td>1002</td>\n",
       "            <td>4</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>480000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>a39231a7-d777-4477-8c66-e0a8a013ac6e</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>130</td>\n",
       "            <td>None</td>\n",
       "            <td>503</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>55000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>c333e861-5fb8-416c-a720-797d32ebd689</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>42</td>\n",
       "            <td>None</td>\n",
       "            <td>410</td>\n",
       "            <td>1</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>38000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>87c5421e-ec24-43c5-8754-108ff4188f3f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>1</td>\n",
       "            <td>None</td>\n",
       "            <td>502</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>42000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1ca35cfb-04fc-4d82-bd15-438552fbe43b</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>93</td>\n",
       "            <td>None</td>\n",
       "            <td>1003</td>\n",
       "            <td>2</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>150000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4eb93eff-ce88-4b2d-94e8-0839fc3e058b</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>62</td>\n",
       "            <td>None</td>\n",
       "            <td>108</td>\n",
       "            <td>4</td>\n",
       "            <td>DANA</td>\n",
       "            <td>64000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>f26b4776-913e-4de2-a0c5-3cb83da9c2a9</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>21</td>\n",
       "            <td>None</td>\n",
       "            <td>111</td>\n",
       "            <td>1</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>12000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>11b7e948-d0e6-4660-bc69-dee1bb5e4bcf</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>33</td>\n",
       "            <td>None</td>\n",
       "            <td>117</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>25000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8cbfedb0-f264-4ccc-b9ac-1b1ea8e56e0c</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>43</td>\n",
       "            <td>None</td>\n",
       "            <td>204</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>35910</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>6c52c49f-9b49-4d26-9f57-c59a8715a103</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>55</td>\n",
       "            <td>None</td>\n",
       "            <td>410</td>\n",
       "            <td>1</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>38000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>337ea2df-b09b-4a5c-badc-c32ac1590f53</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>80</td>\n",
       "            <td>None</td>\n",
       "            <td>302</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5f987c71-a65e-488e-abf3-ad39fec21bbe</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>113</td>\n",
       "            <td>None</td>\n",
       "            <td>407</td>\n",
       "            <td>2</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>90000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3985c3cf-3f76-4e1d-9efa-21977394988f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>17</td>\n",
       "            <td>None</td>\n",
       "            <td>214</td>\n",
       "            <td>2</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>68000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3ae8cc93-8dcd-4d03-969b-666205628059</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>57</td>\n",
       "            <td>None</td>\n",
       "            <td>101</td>\n",
       "            <td>1</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>18498</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0f1259e0-a18f-46b6-b535-106e122c9a56</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>59</td>\n",
       "            <td>None</td>\n",
       "            <td>109</td>\n",
       "            <td>1</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>18000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5496f63c-dc11-40c1-880a-adfbe7c99b26</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>19</td>\n",
       "            <td>None</td>\n",
       "            <td>406</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>23543</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>7c441fe7-ab42-40a7-874a-493b3ceddf2d</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>55</td>\n",
       "            <td>None</td>\n",
       "            <td>410</td>\n",
       "            <td>5</td>\n",
       "            <td>DANA</td>\n",
       "            <td>182481</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>e1e3db63-ef7d-4c76-b92d-a22b21df306f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>122</td>\n",
       "            <td>None</td>\n",
       "            <td>202</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>38913</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>683514f2-ceb8-4f9d-b914-c120c8dcd19f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>49</td>\n",
       "            <td>None</td>\n",
       "            <td>113</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5ab33edf-6e59-4ed3-a8b3-17fa18d0752b</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>109</td>\n",
       "            <td>None</td>\n",
       "            <td>303</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>26000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0dde29a6-baa4-471a-9d24-67ac778eedb3</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>26</td>\n",
       "            <td>None</td>\n",
       "            <td>108</td>\n",
       "            <td>1</td>\n",
       "            <td>Cash</td>\n",
       "            <td>16000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ccf3a171-56dc-4907-ba6c-34ab6712303a</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>28</td>\n",
       "            <td>None</td>\n",
       "            <td>202</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>40000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>72d8567d-894a-45e4-b0b1-87ef310c0c00</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>36</td>\n",
       "            <td>None</td>\n",
       "            <td>305</td>\n",
       "            <td>5</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>110000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3ff350bf-766e-4b15-874e-bc192ef91276</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>20</td>\n",
       "            <td>None</td>\n",
       "            <td>307</td>\n",
       "            <td>1</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>27000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8ce21ea3-db20-456e-9c81-5fe7ceda8bbb</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>26</td>\n",
       "            <td>None</td>\n",
       "            <td>107</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>23000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>d605e770-8a63-4881-bfd0-f9d5a6f2f7b8</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>4</td>\n",
       "            <td>None</td>\n",
       "            <td>112</td>\n",
       "            <td>4</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>72000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3c835dc0-d944-4fa5-80e9-ab30ed2662e9</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>43</td>\n",
       "            <td>None</td>\n",
       "            <td>303</td>\n",
       "            <td>2</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>52000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dd59ba71-36b8-4481-bb3a-4e3e7c52fa17</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>103</td>\n",
       "            <td>None</td>\n",
       "            <td>108</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>16000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>fc3d3348-008d-4127-a104-61e32a25a888</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>100</td>\n",
       "            <td>None</td>\n",
       "            <td>204</td>\n",
       "            <td>1</td>\n",
       "            <td>Cash</td>\n",
       "            <td>39000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>747b6dba-c8fe-4ccd-88b8-d9c6ed3049cf</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>74</td>\n",
       "            <td>None</td>\n",
       "            <td>305</td>\n",
       "            <td>3</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>66000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>fed4057d-bb02-4576-b512-c4c3b253d218</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>125</td>\n",
       "            <td>None</td>\n",
       "            <td>120</td>\n",
       "            <td>1</td>\n",
       "            <td>DANA</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>f7fd5646-37bb-4eec-8bf5-0b52309d258c</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>15</td>\n",
       "            <td>None</td>\n",
       "            <td>415</td>\n",
       "            <td>2</td>\n",
       "            <td>Cash</td>\n",
       "            <td>44000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bf7b539b-0f9a-4a4b-8acd-4e10bc594585</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>81</td>\n",
       "            <td>None</td>\n",
       "            <td>108</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>16000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>80bacd64-7a0e-4fea-958c-a9ba0cd620c2</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>41</td>\n",
       "            <td>None</td>\n",
       "            <td>108</td>\n",
       "            <td>1</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>16000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>d9f195d0-1482-4f53-8201-0c62f5f59b22</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>48</td>\n",
       "            <td>None</td>\n",
       "            <td>109</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>18000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dca02eec-acda-4acc-9165-e21098543881</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>61</td>\n",
       "            <td>None</td>\n",
       "            <td>302</td>\n",
       "            <td>2</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>56000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>91d63f78-e3e9-4e99-b10c-718b1eb0e38a</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>64</td>\n",
       "            <td>None</td>\n",
       "            <td>415</td>\n",
       "            <td>4</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>92192</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>14fcdd54-9e8f-4965-8a2c-827e98326856</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>108</td>\n",
       "            <td>None</td>\n",
       "            <td>602</td>\n",
       "            <td>1</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>70000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>50fd9d3f-85d5-4695-90b2-b633956b8c0c</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>67</td>\n",
       "            <td>None</td>\n",
       "            <td>127</td>\n",
       "            <td>3</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>78000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3d1a85dd-506e-4a9a-b758-588dab73295b</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>68</td>\n",
       "            <td>None</td>\n",
       "            <td>301</td>\n",
       "            <td>3</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>75000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4ccc9bc2-a53f-4a28-abf3-e3fc21813d25</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>118</td>\n",
       "            <td>None</td>\n",
       "            <td>211</td>\n",
       "            <td>2</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>58000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>12922f83-ef8c-485b-807a-30f2edd4253b</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>3</td>\n",
       "            <td>None</td>\n",
       "            <td>309</td>\n",
       "            <td>3</td>\n",
       "            <td>Cash</td>\n",
       "            <td>114000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ff002d4d-9020-49e4-bf9a-b5c29f044aed</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>26</td>\n",
       "            <td>None</td>\n",
       "            <td>110</td>\n",
       "            <td>3</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>75000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>43e42caf-8181-48cc-b691-47eb89a2688b</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>34</td>\n",
       "            <td>None</td>\n",
       "            <td>215</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>3e896c64-e117-4ac3-919c-4ea3e1805081</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>95</td>\n",
       "            <td>None</td>\n",
       "            <td>207</td>\n",
       "            <td>5</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>185000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>8b10550c-d570-4f32-b02c-dd20286218b8</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>78</td>\n",
       "            <td>None</td>\n",
       "            <td>504</td>\n",
       "            <td>4</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>192000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>a76afde6-ce9e-4a11-bcbb-4e59fbddcf7c</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>3</td>\n",
       "            <td>None</td>\n",
       "            <td>603</td>\n",
       "            <td>2</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>116000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ee87905e-4ca4-45ea-8dfa-6a56d12dbc9a</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>27</td>\n",
       "            <td>None</td>\n",
       "            <td>1003</td>\n",
       "            <td>1</td>\n",
       "            <td>Gopay</td>\n",
       "            <td>75000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>e3c43657-1d8c-4bac-83b4-09ef2260e70f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>28</td>\n",
       "            <td>None</td>\n",
       "            <td>703</td>\n",
       "            <td>5</td>\n",
       "            <td>Debit card</td>\n",
       "            <td>100000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>48212ddb-45b8-4cd9-a7cb-6f2a8da01097</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>54</td>\n",
       "            <td>None</td>\n",
       "            <td>609</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>80000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>a25d6b29-afff-4fd2-b41e-f40b57c700aa</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>68</td>\n",
       "            <td>None</td>\n",
       "            <td>405</td>\n",
       "            <td>3</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>87000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>e87d1c78-e7c4-41c7-8049-7b717d106c60</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>14</td>\n",
       "            <td>None</td>\n",
       "            <td>112</td>\n",
       "            <td>4</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>72000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>46d483f3-d450-481c-ac6f-7633a2607723</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>12</td>\n",
       "            <td>None</td>\n",
       "            <td>101</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>18000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>a319dcb4-217d-45a0-8568-11cd5563f616</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>68</td>\n",
       "            <td>None</td>\n",
       "            <td>121</td>\n",
       "            <td>5</td>\n",
       "            <td>Cash</td>\n",
       "            <td>160000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>b4a69f3c-8d3a-4d99-b11c-21c9bdc14f1f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>110</td>\n",
       "            <td>None</td>\n",
       "            <td>412</td>\n",
       "            <td>3</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>81000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>f1eedba3-1343-4e61-9ca3-c4480279b6a6</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>39</td>\n",
       "            <td>None</td>\n",
       "            <td>410</td>\n",
       "            <td>1</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>38000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>951f58d0-5e84-4058-95a8-04eb093923de</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>38</td>\n",
       "            <td>None</td>\n",
       "            <td>306</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>29000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5d59cd2a-4eea-44e7-8ab5-4bde20a04502</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>11</td>\n",
       "            <td>None</td>\n",
       "            <td>216</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>30000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>aabc25fa-3fe1-4e47-ae9b-ec3635c7936c</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>27</td>\n",
       "            <td>None</td>\n",
       "            <td>216</td>\n",
       "            <td>4</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>120000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>dfed2c43-e256-46dc-8f54-86b7c7b5b2bc</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>105</td>\n",
       "            <td>None</td>\n",
       "            <td>505</td>\n",
       "            <td>2</td>\n",
       "            <td>QRIS</td>\n",
       "            <td>103700</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ee0caeb5-ecfe-4b99-a790-cebdbfddc3d9</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>61</td>\n",
       "            <td>None</td>\n",
       "            <td>1001</td>\n",
       "            <td>2</td>\n",
       "            <td>DANA</td>\n",
       "            <td>170000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>cf8ebc5a-ccc5-4569-b9e8-a3692999b735</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>46</td>\n",
       "            <td>None</td>\n",
       "            <td>1003</td>\n",
       "            <td>3</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>225000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>bc8f7d29-2dea-4493-8658-663a698c206f</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>86</td>\n",
       "            <td>None</td>\n",
       "            <td>801</td>\n",
       "            <td>5</td>\n",
       "            <td>DANA</td>\n",
       "            <td>475000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ab7f089a-cd5f-4822-a966-08aaee49f329</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>64</td>\n",
       "            <td>None</td>\n",
       "            <td>205</td>\n",
       "            <td>1</td>\n",
       "            <td>Credit card</td>\n",
       "            <td>28000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1bac27a7-b386-47a4-8991-603f28c13091</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>98</td>\n",
       "            <td>None</td>\n",
       "            <td>1002</td>\n",
       "            <td>1</td>\n",
       "            <td>Ovo</td>\n",
       "            <td>120000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>38f16a81-787f-4425-9bcc-c47709e9db0a</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>52</td>\n",
       "            <td>None</td>\n",
       "            <td>805</td>\n",
       "            <td>3</td>\n",
       "            <td>Cash</td>\n",
       "            <td>225000</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>4e20fd1a-5983-46e3-b5d6-6ed4eb1fa9f2</td>\n",
       "            <td>2023-07-01</td>\n",
       "            <td>59</td>\n",
       "            <td>None</td>\n",
       "            <td>129</td>\n",
       "            <td>2</td>\n",
       "            <td>ShopeePay</td>\n",
       "            <td>52000</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+--------------------------------------+------------+----------+-------------+------------+----------+----------------+--------+\n",
       "|                       transaction_id |       date | store_id | customer_id | product_id | quantity | payment_method |  price |\n",
       "+--------------------------------------+------------+----------+-------------+------------+----------+----------------+--------+\n",
       "| bdd640fb-0667-4ad1-9c80-317fa3b1799d | 2023-07-01 |       71 |        None |        202 |        1 |     Debit card |  40000 |\n",
       "| 1a3d1fa7-bc89-40a9-a3b8-c1e9392456de | 2023-07-01 |       23 |        None |        501 |        1 |           DANA |  40000 |\n",
       "| 17fc695a-07a0-4a6e-8822-e8f36c031199 | 2023-07-01 |       56 |        None |        130 |        1 |           QRIS |  30000 |\n",
       "| 8fadc1a6-06cb-4fb3-9a1d-e644815ef6d1 | 2023-07-01 |       51 |        None |        609 |        1 |           DANA |  80000 |\n",
       "| 6b65a6a4-8b81-48f6-b38a-088ca65ed389 | 2023-07-01 |       57 |        None |        308 |        1 |            Ovo |  35000 |\n",
       "| de8a774b-cf36-458b-8737-819096da1dac | 2023-07-01 |        2 |        None |        705 |        1 |          Gopay |  50000 |\n",
       "| 6c307511-b2b9-437a-a8df-6ec4ce4a2bbd | 2023-07-01 |       88 |        None |        206 |        1 |           DANA |  36000 |\n",
       "| c37459ee-f50b-4a63-b71e-cd7b27cd8130 | 2023-07-01 |       87 |        None |        114 |        1 |           DANA |  28000 |\n",
       "| 5be6128e-18c2-4797-a142-ea7d17be3111 | 2023-07-01 |       89 |        None |        503 |        1 |     Debit card |  55000 |\n",
       "| bacfb3d0-0b1f-4163-8e9f-f57f43b7a3a6 | 2023-07-01 |      118 |        None |        409 |        2 |          Gopay |  96000 |\n",
       "| 60e7a113-ec1b-4ca1-b91e-1d4c1ff49b78 | 2023-07-01 |       21 |        None |        411 |        1 |            Ovo |  33000 |\n",
       "| 9e574f7a-a0ee-49ae-9453-dd324b0dbb41 | 2023-07-01 |       93 |        None |        414 |        2 |     Debit card |  36000 |\n",
       "| 0bbb2599-11ce-4dd2-b45e-d1f03139d32c | 2023-07-01 |       59 |        None |        706 |        5 |           Cash | 225000 |\n",
       "| daf61a26-146d-4f31-bc37-7a4c4a15544d | 2023-07-01 |       60 |        None |       1001 |        2 |           Cash | 170000 |\n",
       "| 7412b293-4729-4739-a14f-f3d719db3ad0 | 2023-07-01 |       94 |        None |        121 |        2 |    Credit card |  64000 |\n",
       "| ab9099a4-35a2-40ae-9af3-05535ec42e08 | 2023-07-01 |       69 |        None |        607 |        4 |          Gopay | 288000 |\n",
       "| 12476f57-a5e5-45ab-aefc-fad8efc89849 | 2023-07-01 |       44 |        None |        409 |        1 |           QRIS |  48000 |\n",
       "| 7656af72-29d4-4eef-beab-edcbbaa80dd4 | 2023-07-01 |       98 |        None |        205 |        1 |          Gopay |  28000 |\n",
       "| b02b61c4-a3d7-4628-ace6-6fa2fd5166e6 | 2023-07-01 |       57 |        None |        605 |        1 |            Ovo |  60000 |\n",
       "| c6a7ee39-c4b0-42cc-97c5-24a55304317f | 2023-07-01 |       15 |        None |        130 |        1 |           QRIS |  30000 |\n",
       "| 50c187fc-ce17-4b4e-8837-b8a3d261a7ab | 2023-07-01 |      103 |        None |        205 |        2 |    Credit card |  56000 |\n",
       "| f16287e4-e9c3-49e0-b602-f8ac10f1bc81 | 2023-07-01 |       81 |        None |        128 |        3 |           QRIS |  78000 |\n",
       "| e27a984d-6548-41d0-bfcd-9eb1a7cad415 | 2023-07-01 |      118 |        None |        119 |        1 |      ShopeePay |  29000 |\n",
       "| beb79919-3f22-4af8-a3be-d01d43cf2fde | 2023-07-01 |       68 |        None |        703 |        5 |           DANA | 100000 |\n",
       "| 956269f0-e5d7-4875-adad-d6c795a76d79 | 2023-07-01 |      103 |        None |        217 |        1 |     Debit card |  29505 |\n",
       "| 2369b584-ff5e-4ff0-bf50-bde4382567b8 | 2023-07-01 |      131 |        None |        404 |        1 |      ShopeePay |  30000 |\n",
       "| dc713d96-0c0f-4195-817a-f08a1745d6d8 | 2023-07-01 |       29 |        None |        120 |        1 |           DANA |  28000 |\n",
       "| ae340454-cac5-468c-a8f4-9481a0a04dc4 | 2023-07-01 |      109 |        None |        502 |        1 |          Gopay |  42000 |\n",
       "| 988c24c9-61b1-4d22-a280-1c4510435a10 | 2023-07-01 |      120 |        None |        408 |        2 |    Credit card |  95069 |\n",
       "| dc5c0eed-8da0-465b-b898-97b9405cacec | 2023-07-01 |        3 |        None |        605 |        1 |     Debit card |  60000 |\n",
       "| e2817efd-ae84-4217-9d53-434bb88139b9 | 2023-07-01 |       69 |        None |        706 |        1 |      ShopeePay |  45000 |\n",
       "| 4b22d308-1c8e-4ee9-9715-bd6fa4161293 | 2023-07-01 |      112 |        None |        121 |        2 |           QRIS |  59361 |\n",
       "| b8db0672-f42d-47cc-80d4-af5974273ca3 | 2023-07-01 |       68 |        None |        405 |        1 |           DANA |  29000 |\n",
       "| e9a1fa6f-81f7-4d1c-adbc-2134c30ff46e | 2023-07-01 |       28 |        None |       1002 |        4 |    Credit card | 480000 |\n",
       "| a39231a7-d777-4477-8c66-e0a8a013ac6e | 2023-07-01 |      130 |        None |        503 |        1 |            Ovo |  55000 |\n",
       "| c333e861-5fb8-416c-a720-797d32ebd689 | 2023-07-01 |       42 |        None |        410 |        1 |      ShopeePay |  38000 |\n",
       "| 87c5421e-ec24-43c5-8754-108ff4188f3f | 2023-07-01 |        1 |        None |        502 |        1 |            Ovo |  42000 |\n",
       "| 1ca35cfb-04fc-4d82-bd15-438552fbe43b | 2023-07-01 |       93 |        None |       1003 |        2 |      ShopeePay | 150000 |\n",
       "| 4eb93eff-ce88-4b2d-94e8-0839fc3e058b | 2023-07-01 |       62 |        None |        108 |        4 |           DANA |  64000 |\n",
       "| f26b4776-913e-4de2-a0c5-3cb83da9c2a9 | 2023-07-01 |       21 |        None |        111 |        1 |           QRIS |  12000 |\n",
       "| 11b7e948-d0e6-4660-bc69-dee1bb5e4bcf | 2023-07-01 |       33 |        None |        117 |        1 |    Credit card |  25000 |\n",
       "| 8cbfedb0-f264-4ccc-b9ac-1b1ea8e56e0c | 2023-07-01 |       43 |        None |        204 |        1 |    Credit card |  35910 |\n",
       "| 6c52c49f-9b49-4d26-9f57-c59a8715a103 | 2023-07-01 |       55 |        None |        410 |        1 |      ShopeePay |  38000 |\n",
       "| 337ea2df-b09b-4a5c-badc-c32ac1590f53 | 2023-07-01 |       80 |        None |        302 |        1 |           DANA |  28000 |\n",
       "| 5f987c71-a65e-488e-abf3-ad39fec21bbe | 2023-07-01 |      113 |        None |        407 |        2 |           QRIS |  90000 |\n",
       "| 3985c3cf-3f76-4e1d-9efa-21977394988f | 2023-07-01 |       17 |        None |        214 |        2 |            Ovo |  68000 |\n",
       "| 3ae8cc93-8dcd-4d03-969b-666205628059 | 2023-07-01 |       57 |        None |        101 |        1 |      ShopeePay |  18498 |\n",
       "| 0f1259e0-a18f-46b6-b535-106e122c9a56 | 2023-07-01 |       59 |        None |        109 |        1 |      ShopeePay |  18000 |\n",
       "| 5496f63c-dc11-40c1-880a-adfbe7c99b26 | 2023-07-01 |       19 |        None |        406 |        1 |           DANA |  23543 |\n",
       "| 7c441fe7-ab42-40a7-874a-493b3ceddf2d | 2023-07-01 |       55 |        None |        410 |        5 |           DANA | 182481 |\n",
       "| e1e3db63-ef7d-4c76-b92d-a22b21df306f | 2023-07-01 |      122 |        None |        202 |        1 |    Credit card |  38913 |\n",
       "| 683514f2-ceb8-4f9d-b914-c120c8dcd19f | 2023-07-01 |       49 |        None |        113 |        1 |    Credit card |  28000 |\n",
       "| 5ab33edf-6e59-4ed3-a8b3-17fa18d0752b | 2023-07-01 |      109 |        None |        303 |        1 |            Ovo |  26000 |\n",
       "| 0dde29a6-baa4-471a-9d24-67ac778eedb3 | 2023-07-01 |       26 |        None |        108 |        1 |           Cash |  16000 |\n",
       "| ccf3a171-56dc-4907-ba6c-34ab6712303a | 2023-07-01 |       28 |        None |        202 |        1 |           DANA |  40000 |\n",
       "| 72d8567d-894a-45e4-b0b1-87ef310c0c00 | 2023-07-01 |       36 |        None |        305 |        5 |     Debit card | 110000 |\n",
       "| 3ff350bf-766e-4b15-874e-bc192ef91276 | 2023-07-01 |       20 |        None |        307 |        1 |     Debit card |  27000 |\n",
       "| 8ce21ea3-db20-456e-9c81-5fe7ceda8bbb | 2023-07-01 |       26 |        None |        107 |        1 |    Credit card |  23000 |\n",
       "| d605e770-8a63-4881-bfd0-f9d5a6f2f7b8 | 2023-07-01 |        4 |        None |        112 |        4 |          Gopay |  72000 |\n",
       "| 3c835dc0-d944-4fa5-80e9-ab30ed2662e9 | 2023-07-01 |       43 |        None |        303 |        2 |          Gopay |  52000 |\n",
       "| dd59ba71-36b8-4481-bb3a-4e3e7c52fa17 | 2023-07-01 |      103 |        None |        108 |        1 |           DANA |  16000 |\n",
       "| fc3d3348-008d-4127-a104-61e32a25a888 | 2023-07-01 |      100 |        None |        204 |        1 |           Cash |  39000 |\n",
       "| 747b6dba-c8fe-4ccd-88b8-d9c6ed3049cf | 2023-07-01 |       74 |        None |        305 |        3 |    Credit card |  66000 |\n",
       "| fed4057d-bb02-4576-b512-c4c3b253d218 | 2023-07-01 |      125 |        None |        120 |        1 |           DANA |  28000 |\n",
       "| f7fd5646-37bb-4eec-8bf5-0b52309d258c | 2023-07-01 |       15 |        None |        415 |        2 |           Cash |  44000 |\n",
       "| bf7b539b-0f9a-4a4b-8acd-4e10bc594585 | 2023-07-01 |       81 |        None |        108 |        1 |    Credit card |  16000 |\n",
       "| 80bacd64-7a0e-4fea-958c-a9ba0cd620c2 | 2023-07-01 |       41 |        None |        108 |        1 |           QRIS |  16000 |\n",
       "| d9f195d0-1482-4f53-8201-0c62f5f59b22 | 2023-07-01 |       48 |        None |        109 |        1 |    Credit card |  18000 |\n",
       "| dca02eec-acda-4acc-9165-e21098543881 | 2023-07-01 |       61 |        None |        302 |        2 |    Credit card |  56000 |\n",
       "| 91d63f78-e3e9-4e99-b10c-718b1eb0e38a | 2023-07-01 |       64 |        None |        415 |        4 |     Debit card |  92192 |\n",
       "| 14fcdd54-9e8f-4965-8a2c-827e98326856 | 2023-07-01 |      108 |        None |        602 |        1 |          Gopay |  70000 |\n",
       "| 50fd9d3f-85d5-4695-90b2-b633956b8c0c | 2023-07-01 |       67 |        None |        127 |        3 |           QRIS |  78000 |\n",
       "| 3d1a85dd-506e-4a9a-b758-588dab73295b | 2023-07-01 |       68 |        None |        301 |        3 |     Debit card |  75000 |\n",
       "| 4ccc9bc2-a53f-4a28-abf3-e3fc21813d25 | 2023-07-01 |      118 |        None |        211 |        2 |          Gopay |  58000 |\n",
       "| 12922f83-ef8c-485b-807a-30f2edd4253b | 2023-07-01 |        3 |        None |        309 |        3 |           Cash | 114000 |\n",
       "| ff002d4d-9020-49e4-bf9a-b5c29f044aed | 2023-07-01 |       26 |        None |        110 |        3 |     Debit card |  75000 |\n",
       "| 43e42caf-8181-48cc-b691-47eb89a2688b | 2023-07-01 |       34 |        None |        215 |        1 |            Ovo |  28000 |\n",
       "| 3e896c64-e117-4ac3-919c-4ea3e1805081 | 2023-07-01 |       95 |        None |        207 |        5 |      ShopeePay | 185000 |\n",
       "| 8b10550c-d570-4f32-b02c-dd20286218b8 | 2023-07-01 |       78 |        None |        504 |        4 |            Ovo | 192000 |\n",
       "| a76afde6-ce9e-4a11-bcbb-4e59fbddcf7c | 2023-07-01 |        3 |        None |        603 |        2 |            Ovo | 116000 |\n",
       "| ee87905e-4ca4-45ea-8dfa-6a56d12dbc9a | 2023-07-01 |       27 |        None |       1003 |        1 |          Gopay |  75000 |\n",
       "| e3c43657-1d8c-4bac-83b4-09ef2260e70f | 2023-07-01 |       28 |        None |        703 |        5 |     Debit card | 100000 |\n",
       "| 48212ddb-45b8-4cd9-a7cb-6f2a8da01097 | 2023-07-01 |       54 |        None |        609 |        1 |            Ovo |  80000 |\n",
       "| a25d6b29-afff-4fd2-b41e-f40b57c700aa | 2023-07-01 |       68 |        None |        405 |        3 |      ShopeePay |  87000 |\n",
       "| e87d1c78-e7c4-41c7-8049-7b717d106c60 | 2023-07-01 |       14 |        None |        112 |        4 |      ShopeePay |  72000 |\n",
       "| 46d483f3-d450-481c-ac6f-7633a2607723 | 2023-07-01 |       12 |        None |        101 |        1 |    Credit card |  18000 |\n",
       "| a319dcb4-217d-45a0-8568-11cd5563f616 | 2023-07-01 |       68 |        None |        121 |        5 |           Cash | 160000 |\n",
       "| b4a69f3c-8d3a-4d99-b11c-21c9bdc14f1f | 2023-07-01 |      110 |        None |        412 |        3 |           QRIS |  81000 |\n",
       "| f1eedba3-1343-4e61-9ca3-c4480279b6a6 | 2023-07-01 |       39 |        None |        410 |        1 |           QRIS |  38000 |\n",
       "| 951f58d0-5e84-4058-95a8-04eb093923de | 2023-07-01 |       38 |        None |        306 |        1 |            Ovo |  29000 |\n",
       "| 5d59cd2a-4eea-44e7-8ab5-4bde20a04502 | 2023-07-01 |       11 |        None |        216 |        1 |            Ovo |  30000 |\n",
       "| aabc25fa-3fe1-4e47-ae9b-ec3635c7936c | 2023-07-01 |       27 |        None |        216 |        4 |            Ovo | 120000 |\n",
       "| dfed2c43-e256-46dc-8f54-86b7c7b5b2bc | 2023-07-01 |      105 |        None |        505 |        2 |           QRIS | 103700 |\n",
       "| ee0caeb5-ecfe-4b99-a790-cebdbfddc3d9 | 2023-07-01 |       61 |        None |       1001 |        2 |           DANA | 170000 |\n",
       "| cf8ebc5a-ccc5-4569-b9e8-a3692999b735 | 2023-07-01 |       46 |        None |       1003 |        3 |            Ovo | 225000 |\n",
       "| bc8f7d29-2dea-4493-8658-663a698c206f | 2023-07-01 |       86 |        None |        801 |        5 |           DANA | 475000 |\n",
       "| ab7f089a-cd5f-4822-a966-08aaee49f329 | 2023-07-01 |       64 |        None |        205 |        1 |    Credit card |  28000 |\n",
       "| 1bac27a7-b386-47a4-8991-603f28c13091 | 2023-07-01 |       98 |        None |       1002 |        1 |            Ovo | 120000 |\n",
       "| 38f16a81-787f-4425-9bcc-c47709e9db0a | 2023-07-01 |       52 |        None |        805 |        3 |           Cash | 225000 |\n",
       "| 4e20fd1a-5983-46e3-b5d6-6ed4eb1fa9f2 | 2023-07-01 |       59 |        None |        129 |        2 |      ShopeePay |  52000 |\n",
       "+--------------------------------------+------------+----------+-------------+------------+----------+----------------+--------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select * from transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a319482-3664-40b3-9010-a68622946f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218baa5c-ed67-46ef-8b01-20329c423835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
